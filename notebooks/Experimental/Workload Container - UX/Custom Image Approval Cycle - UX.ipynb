{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "domain_client = sy.login(email=\"jane@caltech.org\", password=\"my password\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SYS_PACAKGES and PYTHON_PACKAGES as envs to Syft Base Images\n",
    "# docker build syft-base-image-cpu SYS_PACKAGES=\"curl, wget\" PYTHON_PACKAGES=\"pandas=='21.3',matplotlib\" -t custom-image:custom_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HardWare Requirements:**\n",
    "\n",
    "```yaml\n",
    "cpu: 4\n",
    "memory: 16\n",
    "gpu: bool \n",
    "```\n",
    "\n",
    "**Software Requirements:**\n",
    "User defines the apk packages.\n",
    "```yaml\n",
    "build:\n",
    " python_version: \"3.11\"\n",
    " python_packages:\n",
    "   - pytorch==2.0.1\n",
    " system_packages:\n",
    "   - \"ffmpeg\"\n",
    "   - \"ffmpeg\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently the base image is based on Wolfi, but will the DO have requirements of having a syft base image running a different distribution e.g. RedHat, Ubuntu, etc. <br>\n",
    "Maybe at a later stage we can host multiple base images according to distribution\n",
    "- syft-base-wolfi\n",
    "- syft-base-linux\n",
    "- syft-base-redhat ..... etc.\n",
    "\n",
    "and DO can set which base image they want to use for building the custom workload containers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WorkloadEnvironment:\n",
    "    def __init__(self, python_packages: list, system_packages: list, python_version: str):\n",
    "        self.python_packages = python_packages\n",
    "        self.system_packages = system_packages\n",
    "        self.python_version = python_version\n",
    "\n",
    "    @classmethod\n",
    "    def parse_from(cls, file_path: str):\n",
    "        return cls(python_version=\"3.11\", system_packages=[\"ffmpeg\", \"ffmpeg\"], python_packages=[\"pytorch==2.0.1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "workload_env = WorkloadEnvironment.parse_from(file_path=\"/path/config.yaml\")\n",
    "\n",
    "# OR\n",
    "\n",
    "workload_env = WorkloadEnvironment(python_packages=[\"numpy\", \"pandas\"], system_packages=[], python_version=\"3.10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "```\n",
    "\n",
    "Backend -> Worker Managers -> docker run .....\n",
    "\n",
    "Backend -> Worker Manager -> New Manager (Workers)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- what static means, does that mean there are n fixed workers which co\n",
    "- how will the work of splitting the jobs done ? will be equally or can a worker have more jobs\n",
    "- will the consumers can execute the jobs from a queue one at a time or can they run multiple jobs parallely\n",
    "\n",
    "\n",
    "3 consumers:\n",
    "- Launch a subjob, queues that to the Queue (listened by the 3 consumers)\n",
    "- As soons as a consumer is available it executes that job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- which environment\n",
    "- how many environments \n",
    "- hardware requriments for the environment\n",
    "- managing those environments\n",
    "- debugging those environments\n",
    "- tie number containers to a function or a project\n",
    "\n",
    "\n",
    "\n",
    "project = domain_client.project[0]\n",
    "project.init_workers(n=3, cpu=4, memory=16, env=env1)\n",
    "project.init_workers(n=2, cpu=4, memory=16, env=env2)\n",
    "\n",
    "environment = domain_client.workloads.environments[0]\n",
    "enviroment.workers\n",
    "\n",
    "\n",
    "@syft_function(env: env1)\n",
    "def train():\n",
    "    pass\n",
    "\n",
    "\n",
    "@syft_function(env: env1)\n",
    "def main():\n",
    "    for i in [5, 9, 13, 14, 15, 16, 17]:\n",
    "        if i == 13:\n",
    "            train(i, worker=2)\n",
    "        else:\n",
    "            train(i, worker=1)\n",
    "\n",
    "main() -> workload containers be build and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_client.workloads.submit(workload_env=workload_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_client.workloads.environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_client.workloads.enviroments\n",
    "domain_client.workloads.jobs\n",
    "domain_client.workloads.workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Creates a custom dockerfile\n",
    "custom_dockerfile = sy.GenerateDockerfile.from_file(”/path/to/file”)\n",
    "\n",
    "# build the dockerfile locally to test things\n",
    "image_tag = custom_dockerfile.build()\n",
    "\n",
    "\n",
    "\n",
    "abc(asset.mock)\n",
    "\n",
    "# Submit a request for approving the dockerfile\n",
    "request = §§.submit_to(client=domain_client)\n",
    "request.status\n",
    "\n",
    "@syft_function({“x”: asset}, container_image=\"helm:53084c”)\n",
    "def abc(x: int):\n",
    "  return “HEllo”\n",
    "\n",
    "domain_client.images\n",
    "\n",
    "\n",
    "CustomContainerConfigs\n",
    "UID\n",
    "Image Name\n",
    "User Id\n",
    "Status\n",
    "<UUID>\n",
    "hello:asdaf23141415\n",
    "<User-Jane Doe>\n",
    "Approved/Denied\n",
    "\n",
    "\n",
    "\n",
    "Data Owner\n",
    "Do we want to allow access to remote registry or just use remote registry\n",
    "Do we want to allow access single or multiple registry\n",
    "Pass the REGISTRY_URL to the backend container via ENV\n",
    "\n",
    "Question: (to Madhava)\n",
    "Do we want DO to provide a url to the remote registry ?\n",
    "If so then can they provide more than one registry urls\n",
    "If multiple registries are available then how should the DO pass the registry url during the image build and push phase.\n",
    "\n",
    "do_domain_client = sy.login(....)\n",
    "\n",
    "# DO gets the request for custom images\n",
    "custom_image_request = do_domain_client.requests.get_all()[0]\n",
    "# Or\n",
    "custom_image = do_domain_client.images.get_all()[0]\n",
    "\n",
    "# DO can also build the image locally if they want and we can list out the steps to \n",
    "# perform any type of security analysis using synk or trivy.\n",
    "custom_image.build()\n",
    "\n",
    "# approves the custom image\n",
    "build_job = request.approve(blocking=False)\n",
    "#Or\n",
    "workers = custom_image.launch(n_containers=2, timeout=3600)\n",
    "Fetch the docker config\n",
    "Generate the custom dockerfile\n",
    "Build the image from the custom dockerfile\n",
    "We push the image to the local registry\n",
    "Save the details in CustomContainerConfigs table\n",
    "\n",
    "workers[0].logs\n",
    "workers[0].status\n",
    "Building\n",
    "Pushing\n",
    "Running\n",
    "Healthy\n",
    "\n",
    "# denies the custom image\n",
    "request.deny()\n",
    "Save the details in CustomContainerConfigs table\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
