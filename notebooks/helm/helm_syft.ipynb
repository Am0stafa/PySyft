{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "kj/filesystem-disk-unix.c++:1703: warning: PWD environment variable doesn't match current directory; pwd = /home/teo/OpenMined/PySyft\n"
     ]
    }
   ],
   "source": [
    "import syft as sy\n",
    "from syft.store.blob_storage import BlobStorageConfig, BlobStorageClientConfig\n",
    "from syft.store.blob_storage.seaweedfs import SeaweedFSClient, SeaweedFSClientConfig\n",
    "from syft import ActionObject\n",
    "from syft.service.action.action_data_empty import ActionFileData\n",
    "from syft.service.queue.zmq_queue import ZMQQueueConfig, ZMQClientConfig\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staging Protocol Changes...\n",
      "Logged into <test-domain-helm2: High side Domain> as <info@openmined.org>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"alert-warning\" style=\"padding:5px;\"><strong>SyftWarning</strong>: You are using a default password. Please change the password using `[your_client].me.set_password([new_password])`.</div><br />"
      ],
      "text/plain": [
       "SyftWarning: You are using a default password. Please change the password using `[your_client].me.set_password([new_password])`."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "node = sy.orchestra.launch(name=\"test-domain-helm2\", dev_mode=True,\n",
    "                           reset=True,\n",
    "                           n_consumers=4,\n",
    "                           create_producer=True)\n",
    "client = node.login(email=\"info@openmined.org\", password=\"changethis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "docker run --entrypoint /bin/sh -p 8333:8333 -p 8888:8888 chrislusf/seaweedfs -c \"echo 's3.configure -access_key admin -secret_key admin -user iam -actions Read,Write,List,Tagging,Admin -apply' | weed shell > /dev/null 2>&1 & weed server -s3 -s3.port=8333 -master.volumeSizeLimitMB=2048\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_config = BlobStorageConfig(client_type=SeaweedFSClient,\n",
    "                                client_config=SeaweedFSClientConfig(host=\"http://0.0.0.0\",\n",
    "                                                                    port=\"8333\",\n",
    "                                                                    access_key=\"admin\",\n",
    "                                                                    secret_key=\"admin\",\n",
    "                                                                    default_bucket_name=\"test_bucket\",\n",
    "                                                                    region=\"us-east-1\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "node.python_node.init_blob_storage(blob_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fix way we send list of files\n",
    "scenario_obj = ActionObject.from_obj([\n",
    "    sy.ActionObject.from_path(path=\"short_new_scenario.jsonl\").send(client).syft_action_data for i in range(1)])\n",
    "\n",
    "scenario_files_ptr = scenario_obj.send(client)\n",
    "\n",
    "# scenario_obj = ActionObject.from_obj([\n",
    "#     sy.ActionObject.from_path(path=\"scenario_data.jsonl\").send(client).syft_action_data for i in range(2)])\n",
    "\n",
    "# scenario_files_ptr = scenario_obj.send(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fix way we send list of files\n",
    "input_obj = ActionObject.from_obj([\n",
    "    sy.ActionObject.from_path(\"short_input.jsonl\").send(client).syft_action_data for i in range(1)])\n",
    "input_files_ptr = input_obj.send(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for line in input_files_ptr.syft_action_data[0].iter_lines():\n",
    "#     print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Syft functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert-success\" style=\"padding:5px;\"><strong>SyftSuccess</strong>: Syft function 'compute_document_data_overlap' successfully created. To add a code request, please create a project using `project = syft.Project(...)`, then use command `project.create_code_request`.</div><br />"
      ],
      "text/plain": [
       "SyftSuccess: Syft function 'compute_document_data_overlap' successfully created. To add a code request, please create a project using `project = syft.Project(...)`, then use command `project.create_code_request`."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@sy.syft_function()\n",
    "def compute_document_data_overlap(domain, scenario_file, input_files, n):\n",
    "    print(\"starting overlap computation\")\n",
    "    from nltk import ngrams\n",
    "    from collections import defaultdict\n",
    "    from string import punctuation\n",
    "    import re, json\n",
    "\n",
    "    r = re.compile(r\"[\\s{}]+\".format(re.escape(punctuation)))\n",
    "    \n",
    "    def create_ngram_index(light_scenarios, n_values, stats_key_counts):\n",
    "        ngram_index = {n:{}  for n in n_values}\n",
    "        for scenario in light_scenarios:\n",
    "            for n in n_values:\n",
    "                stats_key = scenario['scenario_key'] + '_' + str(n)\n",
    "                stats_key_counts[stats_key] = len(scenario['instances'])\n",
    "                for instance in scenario['instances']:\n",
    "                    id = instance['id']                    \n",
    "                    input_tokens = r.split(instance['input'].lower())\n",
    "                    for input_ngram in ngrams(input_tokens, n):\n",
    "                        if input_ngram not in ngram_index[n]:\n",
    "                            ngram_index[n][input_ngram] = set()\n",
    "                        ngram_index[n][input_ngram].add(stats_key + '+' + id + '+' + 'input')\n",
    "\n",
    "                    # compute reference ngrams\n",
    "                    for reference in instance['references']:\n",
    "                        reference_unigrams = r.split(reference.lower())\n",
    "                        for reference_ngram in ngrams(reference_unigrams, n):\n",
    "                            if reference_ngram not in ngram_index[n]:\n",
    "                                ngram_index[n][reference_ngram] = set()\n",
    "                            ngram_index[n][reference_ngram].add(stats_key + '+' + id + '+' + 'references')\n",
    "        return ngram_index\n",
    "    \n",
    "    # # SETUP\n",
    "    print(\"preparing scenarios and creating indexes\")\n",
    "    light_scenarios = []\n",
    "    for light_scenario_json in scenario_file.iter_lines():\n",
    "        light_scenario_dict: dict = json.loads(light_scenario_json)\n",
    "\n",
    "        light_scenario_key_dict: dict = light_scenario_dict[\"scenario_key\"]\n",
    "        scenario_spec = str(light_scenario_key_dict[\"scenario_spec\"])\n",
    "        light_scenario_key = scenario_spec + '_' + light_scenario_key_dict[\"split\"]\n",
    "        light_instances = [\n",
    "            {\n",
    "                'input': instance_dict['input'], \n",
    "                'references': instance_dict['references'], \n",
    "                'id': instance_dict[\"id\"]\n",
    "            }\n",
    "            for instance_dict in light_scenario_dict[\"instances\"]\n",
    "        ]\n",
    "        light_scenarios.append({'scenario_key': light_scenario_key, 'instances': light_instances})\n",
    "        \n",
    "    stats_key_counts = defaultdict(int)\n",
    "    \n",
    "    ngram_index = create_ngram_index(\n",
    "        light_scenarios=light_scenarios, n_values=[n], stats_key_counts=stats_key_counts\n",
    "    )\n",
    "    \n",
    "    r = re.compile(r\"[\\s{}]+\".format(re.escape(punctuation)))\n",
    "    stats_key_to_input_ids = defaultdict(set)\n",
    "    stats_key_to_reference_ids = defaultdict(set)\n",
    "    entry_overlap_key_to_ngram_counts = {}\n",
    "    print(\"computing overlap\")\n",
    "    \n",
    "#     domain.init_progress(len(input_files))\n",
    "    \n",
    "    for input_file in input_files:\n",
    "        for line in input_file.iter_lines():\n",
    "            document = json.loads(line)[\"text\"]\n",
    "            document_tokens = r.split(document.lower())\n",
    "            for n in ngram_index.keys():\n",
    "                for document_ngram in ngrams(document_tokens, n):\n",
    "                    if document_ngram in ngram_index[n]:\n",
    "                        for entry_overlap_key in ngram_index[n][document_ngram]:\n",
    "                            stats_key, id, part = entry_overlap_key.split(\"+\")\n",
    "                            if part == \"input\":\n",
    "                                stats_key_to_input_ids[stats_key].add(id)\n",
    "                            elif part == \"references\":\n",
    "                                stats_key_to_reference_ids[stats_key].add(id)\n",
    "                            if entry_overlap_key in entry_overlap_key_to_ngram_counts:\n",
    "                                if document_ngram not in entry_overlap_key_to_ngram_counts[entry_overlap_key]:\n",
    "                                    entry_overlap_key_to_ngram_counts[entry_overlap_key][document_ngram] = 0\n",
    "                            else:\n",
    "                                entry_overlap_key_to_ngram_counts[entry_overlap_key] = {}\n",
    "                                entry_overlap_key_to_ngram_counts[entry_overlap_key][document_ngram] = 0\n",
    "                            entry_overlap_key_to_ngram_counts[entry_overlap_key][document_ngram] += 1\n",
    "        domain.update_progress(1)\n",
    "    print(\"done\")\n",
    "    \n",
    "    return stats_key_to_input_ids, stats_key_to_reference_ids, stats_key_counts, entry_overlap_key_to_ngram_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert-success\" style=\"padding:5px;\"><strong>SyftSuccess</strong>: User Code Submitted</div><br />"
      ],
      "text/plain": [
       "SyftSuccess: User Code Submitted"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.code.submit(compute_document_data_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert-success\" style=\"padding:5px;\"><strong>SyftSuccess</strong>: Syft function 'main_function' successfully created. To add a code request, please create a project using `project = syft.Project(...)`, then use command `project.create_code_request`.</div><br />"
      ],
      "text/plain": [
       "SyftSuccess: Syft function 'main_function' successfully created. To add a code request, please create a project using `project = syft.Project(...)`, then use command `project.create_code_request`."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@sy.syft_function_single_use(input_files=input_files_ptr, scenario_files=scenario_files_ptr)\n",
    "def main_function(domain, input_files, scenario_files):\n",
    "    N = [5, 9, 13]\n",
    "    jobs = []\n",
    "    for n in N[:1]:\n",
    "        for scenario_file in scenario_files:\n",
    "            batch_job = domain.launch_job(\n",
    "                compute_document_data_overlap,\n",
    "                scenario_file=scenario_file,\n",
    "                input_files=input_files,\n",
    "                n=n\n",
    "            )\n",
    "            jobs.append(batch_job)\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request approved for domain test-domain-helm2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"alert-success\" style=\"padding:5px;\"><strong>SyftSuccess</strong>: Request db50c9be9bb64ad88a97909793452361 changes applied</div><br />"
      ],
      "text/plain": [
       "SyftSuccess: Request db50c9be9bb64ad88a97909793452361 changes applied"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.code.request_code_execution(main_function)\n",
    "client.requests[-1].approve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = client.code.main_function(input_files=input_files_ptr, scenario_files=scenario_files_ptr, blocking=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "class Job:\n",
       "    id: UID = 5e2c95f2745749f59aa4a283d94e5a7d\n",
       "    status: JobStatus.CREATED\n",
       "    has_parent: False\n",
       "    result: None\n",
       "    logs:\n",
       "\n",
       "0 \n",
       "    \n",
       "```"
      ],
      "text/plain": [
       "syft.service.job.job_stash.Job"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAUNCHING JOB compute_document_data_overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FUNCTION LOG (6157a9c18e744c448adec26361244a3e): starting overlap computation\n",
      "FUNCTION LOG (6157a9c18e744c448adec26361244a3e): preparing scenarios and creating indexes\n",
      "FUNCTION LOG (6157a9c18e744c448adec26361244a3e): computing overlap\n",
      "FUNCTION LOG (6157a9c18e744c448adec26361244a3e): done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pointer:\n",
       "None"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "class Job:\n",
       "    id: UID = 6157a9c18e744c448adec26361244a3e\n",
       "    status: JobStatus.COMPLETED\n",
       "    has_parent: True\n",
       "    result: ActionDataEmpty UID: 68c00a1093504413bf7d2d84e6fe866b <None>\n",
       "    logs:\n",
       "\n",
       "0 starting overlap computation\n",
       "1 preparing scenarios and creating indexes\n",
       "2 computing overlap\n",
       "3 done\n",
       "JOB COMPLETED\n",
       "    \n",
       "```"
      ],
      "text/plain": [
       "syft.service.job.job_stash.Job"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.subjobs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting overlap computation\n",
      "preparing scenarios and creating indexes\n",
      "computing overlap\n",
      "done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "job.subjobs[0].logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [j.wait().get() for j in job.subjobs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_key_to_input_ids, stats_key_to_reference_ids, stats_key_counts, entry_overlap_key_to_ngram_counts = zip(*results)\n",
    "\n",
    "total_input_ids = defaultdict(set)\n",
    "total_reference_ids = defaultdict(set)\n",
    "total_stats_key_counts = defaultdict(int)\n",
    "total_entry_overlap_key_to_ngram_counts = {}\n",
    "\n",
    "for d in stats_key_counts:\n",
    "    for key, val in d.items():\n",
    "        total_stats_key_counts[key] += val\n",
    "\n",
    "\n",
    "for d in stats_key_to_input_ids:\n",
    "    for key in d:\n",
    "        new_set = set()\n",
    "        if key in total_input_ids:\n",
    "            new_set = total_input_ids[key]\n",
    "        new_set = new_set.union(d[key])\n",
    "        total_input_ids[key] = new_set\n",
    "\n",
    "for d in stats_key_to_reference_ids:\n",
    "    for key in d:\n",
    "        new_set = set()\n",
    "        if key in total_reference_ids:\n",
    "            new_set = total_reference_ids[key]\n",
    "        new_set = total_reference_ids[key].union(d[key])\n",
    "        total_reference_ids[key] = new_set\n",
    "        \n",
    "        \n",
    "for d in entry_overlap_key_to_ngram_counts:\n",
    "    for entry_overlap_key in d:\n",
    "        if entry_overlap_key not in total_entry_overlap_key_to_ngram_counts:\n",
    "            total_entry_overlap_key_to_ngram_counts[entry_overlap_key] = {}\n",
    "        for ngram in d[entry_overlap_key]:\n",
    "            if ngram not in total_entry_overlap_key_to_ngram_counts[entry_overlap_key]:\n",
    "                total_entry_overlap_key_to_ngram_counts[entry_overlap_key][ngram] = 0\n",
    "            k = total_entry_overlap_key_to_ngram_counts[entry_overlap_key][ngram]\n",
    "            # total_entry_overlap_key_to_ngram_counts[entry_overlap_key][ngram] = max(k,d[entry_overlap_key][ngram])\n",
    "            total_entry_overlap_key_to_ngram_counts[entry_overlap_key][ngram] = k + d[entry_overlap_key][ngram]\n",
    "        \n",
    "import json\n",
    "\n",
    "all_data_overlap_stats = []\n",
    "for stats_key, count in total_stats_key_counts.items():\n",
    "    data_overlap_stats = {\n",
    "        'data_overlap_stats_key': None,\n",
    "        'num_instances': count,\n",
    "        'instance_ids_with_overlapping_input': sorted(total_input_ids[stats_key]),\n",
    "        'instance_ids_with_overlapping_reference': sorted(total_reference_ids[stats_key]),\n",
    "    }\n",
    "    scenario_spec, split, n_str = stats_key.rsplit('_', 2)\n",
    "\n",
    "    scenario_spec = eval(scenario_spec)\n",
    "    data_overlap_stats['data_overlap_stats_key'] = {\n",
    "        'light_scenario_key': {'scenario_spec': scenario_spec, 'split': split},\n",
    "        'overlap_protocol_spec': {'n': int(n_str)}\n",
    "    }\n",
    "    all_data_overlap_stats.append(data_overlap_stats)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import asdict, is_dataclass\n",
    "\n",
    "def asdict_without_nones(obj):\n",
    "    if not is_dataclass(obj):\n",
    "        raise ValueError(f\"Expected dataclass, got '{obj}'\")\n",
    "    return asdict(obj, dict_factory=lambda x: {k: v for (k, v) in x if v is not None})\n",
    "\n",
    "\n",
    "all_entry_overlap_ngrams = []\n",
    "\n",
    "\n",
    "with open(f\"test_output_ngrams\", \"w\") as f:\n",
    "    for entry_overlap_key in total_entry_overlap_key_to_ngram_counts:\n",
    "        ngram_counts = [\n",
    "            ngram_count for ngram_count in total_entry_overlap_key_to_ngram_counts[entry_overlap_key].items()\n",
    "        ]\n",
    "        args, id, part = entry_overlap_key.rsplit('+', 2)\n",
    "        dic, split, n = args.rsplit('_', 2)\n",
    "        new_entry_overlap_key = {\n",
    "            'stats_key': {\n",
    "                \"light_scenario_key\": {\n",
    "                    'scenario_spec': eval(dic),\n",
    "                    'split': split\n",
    "                },\n",
    "                \"overlap_protocol_spec\": {'n': 5}\n",
    "            },\n",
    "            \"part\": part,\n",
    "            \"instance_id\": id\n",
    "        }\n",
    "        entry_overlap_ngrams = {\n",
    "            'entry_data_overlap_key': new_entry_overlap_key, \n",
    "            'overlapping_ngram_counts': ngram_counts\n",
    "        }\n",
    "        all_entry_overlap_ngrams.append(entry_overlap_ngrams)\n",
    "        f.write(f\"{json.dumps(entry_overlap_ngrams)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add helm to Python_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import get_metrics\n",
    "metrics_list = get_metrics(\"test_output_ngrams\", \"short_new_scenario.jsonl\", \"new_metrics\", '', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "[EntryOverlapMetric(entry_data_overlap_key=EntryDataOverlapKey(stats_key=DataOverlapStatsKey(light_scenario_key=LightScenarioKey(scenario_spec=ScenarioSpec(class_name=&#x27;helm.benchmark.scenarios.summarization_scenario.SummarizationScenario&#x27;, args={&#x27;dataset_name&#x27;: &#x27;xsum-sampled&#x27;, &#x27;sampling_min_length&#x27;: 50, &#x27;sampling_max_length&#x27;: 150, &#x27;doc_max_length&#x27;: 512}), split=&#x27;valid&#x27;), overlap_protocol_spec=OverlapProtocolSpec(n=5)), part=&#x27;input&#x27;, instance_id=&#x27;id8967&#x27;), overlap_metric=OverlapMetric(metric_score=1, metric_protocol_spec=MetricProtocolSpec(partial_overlap_spec=&lt;PartialOverlapSpec.binary: 0&gt;, frequency_spec=FrequencySpec(filter_value=0, weighting=False)))), EntryOverlapMetric(entry_data_overlap_key=EntryDataOverlapKey(stats_key=DataOverlapStatsKey(light_scenario_key=LightScenarioKey(scenario_spec=ScenarioSpec(class_name=&#x27;helm.benchmark.scenarios.summarization_scenario.SummarizationScenario&#x27;, args={&#x27;dataset_name&#x27;: &#x27;xsum-sampled&#x27;, &#x27;sampling_min_length&#x27;: 50, &#x27;sampling_max_length&#x27;: 150, &#x27;doc_max_length&#x27;: 512}), split=&#x27;valid&#x27;), overlap_protocol_spec=OverlapProtocolSpec(n=5)), part=&#x27;input&#x27;, instance_id=&#x27;id8967&#x27;), overlap_metric=OverlapMetric(metric_score=0.006666666666666667, metric_protocol_spec=MetricProtocolSpec(partial_overlap_spec=&lt;PartialOverlapSpec.jaccard: 1&gt;, frequency_spec=FrequencySpec(filter_value=0, weighting=False)))), EntryOverlapMetric(entry_data_overlap_key=EntryDataOverlapKey(stats_key=DataOverlapStatsKey(light_scenario_key=LightScenarioKey(scenario_spec=ScenarioSpec(class_name=&#x27;helm.benchmark.scenarios.summarization_scenario.SummarizationScenario&#x27;, args={&#x27;dataset_name&#x27;: &#x27;xsum-sampled&#x27;, &#x27;sampling_min_length&#x27;: 50, &#x27;sampling_max_length&#x27;: 150, &#x27;doc_max_length&#x27;: 512}), split=&#x27;valid&#x27;), overlap_protocol_spec=OverlapProtocolSpec(n=5)), part=&#x27;input&#x27;, instance_id=&#x27;id8967&#x27;), overlap_metric=OverlapMetric(metric_score=0.006666666666666667, metric_protocol_spec=MetricProtocolSpec(partial_overlap_spec=&lt;PartialOverlapSpec.jaccard: 1&gt;, frequency_spec=FrequencySpec(filter_value=0, weighting=True)))), EntryOverlapMetric(entry_data_overlap_key=EntryDataOverlapKey(stats_key=DataOverlapStatsKey(light_scenario_key=LightScenarioKey(scenario_spec=ScenarioSpec(class_name=&#x27;helm.benchmark.scenarios.summarization_scenario.SummarizationScenario&#x27;, args={&#x27;dataset_name&#x27;: &#x27;xsum-sampled&#x27;, &#x27;sampling_min_length&#x27;: 50, &#x27;sampling_max_length&#x27;: 150, &#x27;doc_max_length&#x27;: 512}), split=&#x27;valid&#x27;), overlap_protocol_spec=OverlapProtocolSpec(n=5)), part=&#x27;input&#x27;, instance_id=&#x27;id8967&#x27;), overlap_metric=OverlapMetric(metric_score=0.019736842105263157, metric_protocol_spec=MetricProtocolSpec(partial_overlap_spec=&lt;PartialOverlapSpec.token: 2&gt;, frequency_spec=FrequencySpec(filter_value=0, weighting=False)))), EntryOverlapMetric(entry_data_overlap_key=EntryDataOverlapKey(stats_key=DataOverlapStatsKey(light_scenario_key=LightScenarioKey(scenario_spec=ScenarioSpec(class_name=&#x27;helm.benchmark.scenarios.summarization_scenario.SummarizationScenario&#x27;, args={&#x27;dataset_name&#x27;: &#x27;xsum-sampled&#x27;, &#x27;sampling_min_length&#x27;: 50, &#x27;sampling_max_length&#x27;: 150, &#x27;doc_max_length&#x27;: 512}), split=&#x27;valid&#x27;), overlap_protocol_spec=OverlapProtocolSpec(n=5)), part=&#x27;input&#x27;, instance_id=&#x27;id8967&#x27;), overlap_metric=OverlapMetric(metric_score=0.019736842105263157, metric_protocol_spec=MetricProtocolSpec(partial_overlap_spec=&lt;PartialOverlapSpec.token: 2&gt;, frequency_spec=FrequencySpec(filter_value=0, weighting=True)))), EntryOverlapMetric(entry_data_overlap_key=EntryDataOverlapKey(stats_key=DataOverlapStatsKey(light_scenario_key=LightScenarioKey(scenario_spec=ScenarioSpec(class_name=&#x27;helm.benchmark.scenarios.summarization_scenario.SummarizationScenario&#x27;, args={&#x27;dataset_name&#x27;: &#x27;xsum-sampled&#x27;, &#x27;sampling_min_length&#x27;: 50, &#x27;sampling_max_length&#x27;: 150, &#x27;doc_max_length&#x27;: 512}), split=&#x27;valid&#x27;), overlap_protocol_spec=OverlapProtocolSpec(n=5)), part=&#x27;input&#x27;, instance_id=&#x27;id8967&#x27;), overlap_metric=OverlapMetric(metric_score=1, metric_protocol_spec=MetricProtocolSpec(partial_overlap_spec=&lt;PartialOverlapSpec.binary: 0&gt;, frequency_spec=FrequencySpec(filter_value=10, weighting=False)))), EntryOverlapMetric(entry_data_overlap_key=EntryDataOverlapKey(stats_key=DataOverlapStatsKey(light_scenario_key=LightScenarioKey(scenario_spec=ScenarioSpec(class_name=&#x27;helm.benchmark.scenarios.summarization_scenario.SummarizationScenario&#x27;, args={&#x27;dataset_name&#x27;: &#x27;xsum-sampled&#x27;, &#x27;sampling_min_length&#x27;: 50, &#x27;sampling_max_length&#x27;: 150, &#x27;doc_max_length&#x27;: 512}), split=&#x27;valid&#x27;), overlap_protocol_spec=OverlapProtocolSpec(n=5)), part=&#x27;input&#x27;, instance_id=&#x27;id8967&#x27;), overlap_metric=OverlapMetric(metric_score=0.006666666666666667, metric_protocol_spec=MetricProtocolSpec(partial_overlap_spec=&lt;PartialOverlapSpec.jaccard: 1&gt;, frequency_spec=FrequencySpec(filter_value=10, weighting=False)))), EntryOverlapMetric(entry_data_overlap_key=EntryDataOverlapKey(stats_key=DataOverlapStatsKey(light_scenario_key=LightScenarioKey(scenario_spec=ScenarioSpec(class_name=&#x27;helm.benchmark.scenarios.summarization_scenario.SummarizationScenario&#x27;, args={&#x27;dataset_name&#x27;: &#x27;xsum-sampled&#x27;, &#x27;sampling_min_length&#x27;: 50, &#x27;sampling_max_length&#x27;: 150, &#x27;doc_max_length&#x27;: 512}), split=&#x27;valid&#x27;), overlap_protocol_spec=OverlapProtocolSpec(n=5)), part=&#x27;input&#x27;, instance_id=&#x27;id8967&#x27;), overlap_metric=OverlapMetric(metric_score=0.006666666666666667, metric_protocol_spec=MetricProtocolSpec(partial_overlap_spec=&lt;PartialOverlapSpec.jaccard: 1&gt;, frequency_spec=FrequencySpec(filter_value=10, weighting=True)))), EntryOverlapMetric(entry_data_overlap_key=EntryDataOverlapKey(stats_key=DataOverlapStatsKey(light_scenario_key=LightScenarioKey(scenario_spec=ScenarioSpec(class_name=&#x27;helm.benchmark.scenarios.summarization_scenario.SummarizationScenario&#x27;, args={&#x27;dataset_name&#x27;: &#x27;xsum-sampled&#x27;, &#x27;sampling_min_length&#x27;: 50, &#x27;sampling_max_length&#x27;: 150, &#x27;doc_max_length&#x27;: 512}), split=&#x27;valid&#x27;), overlap_protocol_spec=OverlapProtocolSpec(n=5)), part=&#x27;input&#x27;, instance_id=&#x27;id8967&#x27;), overlap_metric=OverlapMetric(metric_score=0.019736842105263157, metric_protocol_spec=MetricProtocolSpec(partial_overlap_spec=&lt;PartialOverlapSpec.token: 2&gt;, frequency_spec=FrequencySpec(filter_value=10, weighting=False)))), EntryOverlapMetric(entry_data_overlap_key=EntryDataOverlapKey(stats_key=DataOverlapStatsKey(light_scenario_key=LightScenarioKey(scenario_spec=ScenarioSpec(class_name=&#x27;helm.benchmark.scenarios.summarization_scenario.SummarizationScenario&#x27;, args={&#x27;dataset_name&#x27;: &#x27;xsum-sampled&#x27;, &#x27;sampling_min_length&#x27;: 50, &#x27;sampling_max_length&#x27;: 150, &#x27;doc_max_length&#x27;: 512}), split=&#x27;valid&#x27;), overlap_protocol_spec=OverlapProtocolSpec(n=5)), part=&#x27;input&#x27;, instance_id=&#x27;id8967&#x27;), overlap_metric=OverlapMetric(metric_score=0.019736842105263157, metric_protocol_spec=MetricProtocolSpec(partial_overlap_spec=&lt;PartialOverlapSpec.token: 2&gt;, frequency_spec=FrequencySpec(filter_value=10, weighting=True))))]"
      ],
      "text/plain": [
       "[EntryOverlapMetric(entry_data_overlap_key=EntryDataOverlapKey(stats_key=DataOverlapStatsKey(light_scenario_key=LightScenarioKey(scenario_spec=ScenarioSpec(class_name='helm.benchmark.scenarios.summarization_scenario.SummarizationScenario', args={'dataset_name': 'xsum-sampled', 'sampling_min_length': 50, 'sampling_max_length': 150, 'doc_max_length': 512}), split='valid'), overlap_protocol_spec=OverlapProtocolSpec(n=5)), part='input', instance_id='id8967'), overlap_metric=OverlapMetric(metric_score=1, metric_protocol_spec=MetricProtocolSpec(partial_overlap_spec=<PartialOverlapSpec.binary: 0>, frequency_spec=FrequencySpec(filter_value=0, weighting=False)))),\n",
       " EntryOverlapMetric(entry_data_overlap_key=EntryDataOverlapKey(stats_key=DataOverlapStatsKey(light_scenario_key=LightScenarioKey(scenario_spec=ScenarioSpec(class_name='helm.benchmark.scenarios.summarization_scenario.SummarizationScenario', args={'dataset_name': 'xsum-sampled', 'sampling_min_length': 50, 'sampling_max_length': 150, 'doc_max_length': 512}), split='valid'), overlap_protocol_spec=OverlapProtocolSpec(n=5)), part='input', instance_id='id8967'), overlap_metric=OverlapMetric(metric_score=0.006666666666666667, metric_protocol_spec=MetricProtocolSpec(partial_overlap_spec=<PartialOverlapSpec.jaccard: 1>, frequency_spec=FrequencySpec(filter_value=0, weighting=False)))),\n",
       " EntryOverlapMetric(entry_data_overlap_key=EntryDataOverlapKey(stats_key=DataOverlapStatsKey(light_scenario_key=LightScenarioKey(scenario_spec=ScenarioSpec(class_name='helm.benchmark.scenarios.summarization_scenario.SummarizationScenario', args={'dataset_name': 'xsum-sampled', 'sampling_min_length': 50, 'sampling_max_length': 150, 'doc_max_length': 512}), split='valid'), overlap_protocol_spec=OverlapProtocolSpec(n=5)), part='input', instance_id='id8967'), overlap_metric=OverlapMetric(metric_score=0.006666666666666667, metric_protocol_spec=MetricProtocolSpec(partial_overlap_spec=<PartialOverlapSpec.jaccard: 1>, frequency_spec=FrequencySpec(filter_value=0, weighting=True)))),\n",
       " EntryOverlapMetric(entry_data_overlap_key=EntryDataOverlapKey(stats_key=DataOverlapStatsKey(light_scenario_key=LightScenarioKey(scenario_spec=ScenarioSpec(class_name='helm.benchmark.scenarios.summarization_scenario.SummarizationScenario', args={'dataset_name': 'xsum-sampled', 'sampling_min_length': 50, 'sampling_max_length': 150, 'doc_max_length': 512}), split='valid'), overlap_protocol_spec=OverlapProtocolSpec(n=5)), part='input', instance_id='id8967'), overlap_metric=OverlapMetric(metric_score=0.019736842105263157, metric_protocol_spec=MetricProtocolSpec(partial_overlap_spec=<PartialOverlapSpec.token: 2>, frequency_spec=FrequencySpec(filter_value=0, weighting=False)))),\n",
       " EntryOverlapMetric(entry_data_overlap_key=EntryDataOverlapKey(stats_key=DataOverlapStatsKey(light_scenario_key=LightScenarioKey(scenario_spec=ScenarioSpec(class_name='helm.benchmark.scenarios.summarization_scenario.SummarizationScenario', args={'dataset_name': 'xsum-sampled', 'sampling_min_length': 50, 'sampling_max_length': 150, 'doc_max_length': 512}), split='valid'), overlap_protocol_spec=OverlapProtocolSpec(n=5)), part='input', instance_id='id8967'), overlap_metric=OverlapMetric(metric_score=0.019736842105263157, metric_protocol_spec=MetricProtocolSpec(partial_overlap_spec=<PartialOverlapSpec.token: 2>, frequency_spec=FrequencySpec(filter_value=0, weighting=True)))),\n",
       " EntryOverlapMetric(entry_data_overlap_key=EntryDataOverlapKey(stats_key=DataOverlapStatsKey(light_scenario_key=LightScenarioKey(scenario_spec=ScenarioSpec(class_name='helm.benchmark.scenarios.summarization_scenario.SummarizationScenario', args={'dataset_name': 'xsum-sampled', 'sampling_min_length': 50, 'sampling_max_length': 150, 'doc_max_length': 512}), split='valid'), overlap_protocol_spec=OverlapProtocolSpec(n=5)), part='input', instance_id='id8967'), overlap_metric=OverlapMetric(metric_score=1, metric_protocol_spec=MetricProtocolSpec(partial_overlap_spec=<PartialOverlapSpec.binary: 0>, frequency_spec=FrequencySpec(filter_value=10, weighting=False)))),\n",
       " EntryOverlapMetric(entry_data_overlap_key=EntryDataOverlapKey(stats_key=DataOverlapStatsKey(light_scenario_key=LightScenarioKey(scenario_spec=ScenarioSpec(class_name='helm.benchmark.scenarios.summarization_scenario.SummarizationScenario', args={'dataset_name': 'xsum-sampled', 'sampling_min_length': 50, 'sampling_max_length': 150, 'doc_max_length': 512}), split='valid'), overlap_protocol_spec=OverlapProtocolSpec(n=5)), part='input', instance_id='id8967'), overlap_metric=OverlapMetric(metric_score=0.006666666666666667, metric_protocol_spec=MetricProtocolSpec(partial_overlap_spec=<PartialOverlapSpec.jaccard: 1>, frequency_spec=FrequencySpec(filter_value=10, weighting=False)))),\n",
       " EntryOverlapMetric(entry_data_overlap_key=EntryDataOverlapKey(stats_key=DataOverlapStatsKey(light_scenario_key=LightScenarioKey(scenario_spec=ScenarioSpec(class_name='helm.benchmark.scenarios.summarization_scenario.SummarizationScenario', args={'dataset_name': 'xsum-sampled', 'sampling_min_length': 50, 'sampling_max_length': 150, 'doc_max_length': 512}), split='valid'), overlap_protocol_spec=OverlapProtocolSpec(n=5)), part='input', instance_id='id8967'), overlap_metric=OverlapMetric(metric_score=0.006666666666666667, metric_protocol_spec=MetricProtocolSpec(partial_overlap_spec=<PartialOverlapSpec.jaccard: 1>, frequency_spec=FrequencySpec(filter_value=10, weighting=True)))),\n",
       " EntryOverlapMetric(entry_data_overlap_key=EntryDataOverlapKey(stats_key=DataOverlapStatsKey(light_scenario_key=LightScenarioKey(scenario_spec=ScenarioSpec(class_name='helm.benchmark.scenarios.summarization_scenario.SummarizationScenario', args={'dataset_name': 'xsum-sampled', 'sampling_min_length': 50, 'sampling_max_length': 150, 'doc_max_length': 512}), split='valid'), overlap_protocol_spec=OverlapProtocolSpec(n=5)), part='input', instance_id='id8967'), overlap_metric=OverlapMetric(metric_score=0.019736842105263157, metric_protocol_spec=MetricProtocolSpec(partial_overlap_spec=<PartialOverlapSpec.token: 2>, frequency_spec=FrequencySpec(filter_value=10, weighting=False)))),\n",
       " EntryOverlapMetric(entry_data_overlap_key=EntryDataOverlapKey(stats_key=DataOverlapStatsKey(light_scenario_key=LightScenarioKey(scenario_spec=ScenarioSpec(class_name='helm.benchmark.scenarios.summarization_scenario.SummarizationScenario', args={'dataset_name': 'xsum-sampled', 'sampling_min_length': 50, 'sampling_max_length': 150, 'doc_max_length': 512}), split='valid'), overlap_protocol_spec=OverlapProtocolSpec(n=5)), part='input', instance_id='id8967'), overlap_metric=OverlapMetric(metric_score=0.019736842105263157, metric_protocol_spec=MetricProtocolSpec(partial_overlap_spec=<PartialOverlapSpec.token: 2>, frequency_spec=FrequencySpec(filter_value=10, weighting=True))))]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_list[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "[5, 5, 5, 5, 5, 5, 5, 5, 5, 5]"
      ],
      "text/plain": [
       "[5, 5, 5, 5, 5, 5, 5, 5, 5, 5]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m.entry_data_overlap_key.stats_key.overlap_protocol_spec.n for m in metrics_list[0:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_metrics(metrics_list):\n",
    "    merged_metrics = []\n",
    "    for i in range(len(metrics_list)//10):\n",
    "        group_metrics = {\n",
    "            \"entry_data_overlap_key\": metrics_list[10*i].entry_data_overlap_key,\n",
    "            \"metrics\": [m.overlap_metric for m in metrics_list[10*i:10*(i+1)]]\n",
    "        }\n",
    "        merged_metrics.append(group_metrics)\n",
    "    return merged_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_metrics = merge_metrics(metrics_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_to_cols(metrics):\n",
    "    entry_data_overlap_key = metrics['entry_data_overlap_key']\n",
    "    stats_key = entry_data_overlap_key.stats_key\n",
    "    scenario_spec = stats_key.light_scenario_key.scenario_spec\n",
    "    class_name = '.'.join(scenario_spec.class_name.split('.')[-2:])\n",
    "    args = scenario_spec.args\n",
    "    split = stats_key.light_scenario_key.split\n",
    "    n = stats_key.overlap_protocol_spec.n\n",
    "    binary_score = metrics['metrics'][0].metric_score\n",
    "    jaccard_unweighted = metrics['metrics'][1].metric_score\n",
    "    jaccard_weighted = metrics['metrics'][2].metric_score\n",
    "    token_unweighted = metrics['metrics'][3].metric_score\n",
    "    token_weighted = metrics['metrics'][4].metric_score\n",
    "    return [class_name, args, split, n, binary_score, jaccard_unweighted, jaccard_weighted, token_unweighted, token_weighted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['class_name', 'args', 'split', 'n', 'binary', 'jaccard_unweighted', 'jaccard_weighted', 'token_unweighted', 'token_weighted']\n",
    "metrics_rows = [metrics_to_cols(metrics) for metrics in new_metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(metrics_rows, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_name</th>\n",
       "      <th>args</th>\n",
       "      <th>split</th>\n",
       "      <th>n</th>\n",
       "      <th>binary</th>\n",
       "      <th>jaccard_unweighted</th>\n",
       "      <th>jaccard_weighted</th>\n",
       "      <th>token_unweighted</th>\n",
       "      <th>token_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>valid</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.019737</td>\n",
       "      <td>0.019737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>valid</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001916</td>\n",
       "      <td>0.001916</td>\n",
       "      <td>0.009506</td>\n",
       "      <td>0.009506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>test</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.009488</td>\n",
       "      <td>0.009488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>valid</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.009766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>valid</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002710</td>\n",
       "      <td>0.002710</td>\n",
       "      <td>0.013405</td>\n",
       "      <td>0.013405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>valid</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002066</td>\n",
       "      <td>0.002066</td>\n",
       "      <td>0.010246</td>\n",
       "      <td>0.010246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>valid</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.009434</td>\n",
       "      <td>0.009434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>valid</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001946</td>\n",
       "      <td>0.001946</td>\n",
       "      <td>0.009653</td>\n",
       "      <td>0.009653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>valid</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003268</td>\n",
       "      <td>0.003268</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.016129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>test</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.009524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>valid</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>0.019763</td>\n",
       "      <td>0.019763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>valid</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>0.013298</td>\n",
       "      <td>0.013298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>test</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>valid</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003861</td>\n",
       "      <td>0.003861</td>\n",
       "      <td>0.019011</td>\n",
       "      <td>0.019011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>test</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.011905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>test</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002755</td>\n",
       "      <td>0.002755</td>\n",
       "      <td>0.013624</td>\n",
       "      <td>0.013624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>valid</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.018657</td>\n",
       "      <td>0.018657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>test</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.030488</td>\n",
       "      <td>0.030488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>test</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010526</td>\n",
       "      <td>0.010526</td>\n",
       "      <td>0.050505</td>\n",
       "      <td>0.050505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>valid</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005263</td>\n",
       "      <td>0.005263</td>\n",
       "      <td>0.025773</td>\n",
       "      <td>0.025773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>test</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002933</td>\n",
       "      <td>0.002933</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.014493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>valid</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.036585</td>\n",
       "      <td>0.036585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>test</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004673</td>\n",
       "      <td>0.004673</td>\n",
       "      <td>0.022936</td>\n",
       "      <td>0.022936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>valid</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003759</td>\n",
       "      <td>0.003759</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.018519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>test</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006116</td>\n",
       "      <td>0.006116</td>\n",
       "      <td>0.030211</td>\n",
       "      <td>0.030211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>valid</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001873</td>\n",
       "      <td>0.001873</td>\n",
       "      <td>0.009294</td>\n",
       "      <td>0.009294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>twitter_aae_scenario.TwitterAAEScenario</td>\n",
       "      <td>{'demographic': 'white'}</td>\n",
       "      <td>test</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>twitter_aae_scenario.TwitterAAEScenario</td>\n",
       "      <td>{'demographic': 'white'}</td>\n",
       "      <td>test</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>valid</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001946</td>\n",
       "      <td>0.001946</td>\n",
       "      <td>0.009653</td>\n",
       "      <td>0.009653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>valid</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002227</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>0.011038</td>\n",
       "      <td>0.005519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>test</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003115</td>\n",
       "      <td>0.001558</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.007692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>valid</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004386</td>\n",
       "      <td>0.004386</td>\n",
       "      <td>0.021552</td>\n",
       "      <td>0.021552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>test</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>0.015244</td>\n",
       "      <td>0.015244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>valid</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.045045</td>\n",
       "      <td>0.045045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>valid</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>0.024631</td>\n",
       "      <td>0.024631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>test</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.013736</td>\n",
       "      <td>0.013736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>test</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.014837</td>\n",
       "      <td>0.014837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>valid</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.011261</td>\n",
       "      <td>0.011261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>valid</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006993</td>\n",
       "      <td>0.006993</td>\n",
       "      <td>0.034014</td>\n",
       "      <td>0.034014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>valid</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001873</td>\n",
       "      <td>0.001873</td>\n",
       "      <td>0.009294</td>\n",
       "      <td>0.009294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>valid</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001946</td>\n",
       "      <td>0.001946</td>\n",
       "      <td>0.009653</td>\n",
       "      <td>0.009653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>valid</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>valid</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003839</td>\n",
       "      <td>0.003839</td>\n",
       "      <td>0.011429</td>\n",
       "      <td>0.011429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>valid</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>0.009634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>valid</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003810</td>\n",
       "      <td>0.003810</td>\n",
       "      <td>0.011342</td>\n",
       "      <td>0.011342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>valid</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001949</td>\n",
       "      <td>0.001949</td>\n",
       "      <td>0.009671</td>\n",
       "      <td>0.009671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>test</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.018939</td>\n",
       "      <td>0.018939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>valid</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002967</td>\n",
       "      <td>0.002967</td>\n",
       "      <td>0.014663</td>\n",
       "      <td>0.014663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>twitter_aae_scenario.TwitterAAEScenario</td>\n",
       "      <td>{'demographic': 'white'}</td>\n",
       "      <td>test</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.227273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>twitter_aae_scenario.TwitterAAEScenario</td>\n",
       "      <td>{'demographic': 'white'}</td>\n",
       "      <td>test</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>valid</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>0.012755</td>\n",
       "      <td>0.006378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>twitter_aae_scenario.TwitterAAEScenario</td>\n",
       "      <td>{'demographic': 'white'}</td>\n",
       "      <td>test</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>valid</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>0.015198</td>\n",
       "      <td>0.015198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>valid</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>0.010081</td>\n",
       "      <td>0.010081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>summarization_scenario.SummarizationScenario</td>\n",
       "      <td>{'dataset_name': 'xsum-sampled', 'sampling_min...</td>\n",
       "      <td>test</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001949</td>\n",
       "      <td>0.001949</td>\n",
       "      <td>0.009671</td>\n",
       "      <td>0.009671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      class_name  \\\n",
       "0   summarization_scenario.SummarizationScenario   \n",
       "1   summarization_scenario.SummarizationScenario   \n",
       "2   summarization_scenario.SummarizationScenario   \n",
       "3   summarization_scenario.SummarizationScenario   \n",
       "4   summarization_scenario.SummarizationScenario   \n",
       "5   summarization_scenario.SummarizationScenario   \n",
       "6   summarization_scenario.SummarizationScenario   \n",
       "7   summarization_scenario.SummarizationScenario   \n",
       "8   summarization_scenario.SummarizationScenario   \n",
       "9   summarization_scenario.SummarizationScenario   \n",
       "10  summarization_scenario.SummarizationScenario   \n",
       "11  summarization_scenario.SummarizationScenario   \n",
       "12  summarization_scenario.SummarizationScenario   \n",
       "13  summarization_scenario.SummarizationScenario   \n",
       "14  summarization_scenario.SummarizationScenario   \n",
       "15  summarization_scenario.SummarizationScenario   \n",
       "16  summarization_scenario.SummarizationScenario   \n",
       "17  summarization_scenario.SummarizationScenario   \n",
       "18  summarization_scenario.SummarizationScenario   \n",
       "19  summarization_scenario.SummarizationScenario   \n",
       "20  summarization_scenario.SummarizationScenario   \n",
       "21  summarization_scenario.SummarizationScenario   \n",
       "22  summarization_scenario.SummarizationScenario   \n",
       "23  summarization_scenario.SummarizationScenario   \n",
       "24  summarization_scenario.SummarizationScenario   \n",
       "25  summarization_scenario.SummarizationScenario   \n",
       "26       twitter_aae_scenario.TwitterAAEScenario   \n",
       "27       twitter_aae_scenario.TwitterAAEScenario   \n",
       "28  summarization_scenario.SummarizationScenario   \n",
       "29  summarization_scenario.SummarizationScenario   \n",
       "30  summarization_scenario.SummarizationScenario   \n",
       "31  summarization_scenario.SummarizationScenario   \n",
       "32  summarization_scenario.SummarizationScenario   \n",
       "33  summarization_scenario.SummarizationScenario   \n",
       "34  summarization_scenario.SummarizationScenario   \n",
       "35  summarization_scenario.SummarizationScenario   \n",
       "36  summarization_scenario.SummarizationScenario   \n",
       "37  summarization_scenario.SummarizationScenario   \n",
       "38  summarization_scenario.SummarizationScenario   \n",
       "39  summarization_scenario.SummarizationScenario   \n",
       "40  summarization_scenario.SummarizationScenario   \n",
       "41  summarization_scenario.SummarizationScenario   \n",
       "42  summarization_scenario.SummarizationScenario   \n",
       "43  summarization_scenario.SummarizationScenario   \n",
       "44  summarization_scenario.SummarizationScenario   \n",
       "45  summarization_scenario.SummarizationScenario   \n",
       "46  summarization_scenario.SummarizationScenario   \n",
       "47  summarization_scenario.SummarizationScenario   \n",
       "48       twitter_aae_scenario.TwitterAAEScenario   \n",
       "49       twitter_aae_scenario.TwitterAAEScenario   \n",
       "50  summarization_scenario.SummarizationScenario   \n",
       "51       twitter_aae_scenario.TwitterAAEScenario   \n",
       "52  summarization_scenario.SummarizationScenario   \n",
       "53  summarization_scenario.SummarizationScenario   \n",
       "54  summarization_scenario.SummarizationScenario   \n",
       "\n",
       "                                                 args  split  n  binary  \\\n",
       "0   {'dataset_name': 'xsum-sampled', 'sampling_min...  valid  5       1   \n",
       "1   {'dataset_name': 'xsum-sampled', 'sampling_min...  valid  5       1   \n",
       "2   {'dataset_name': 'xsum-sampled', 'sampling_min...   test  5       1   \n",
       "3   {'dataset_name': 'xsum-sampled', 'sampling_min...  valid  5       1   \n",
       "4   {'dataset_name': 'xsum-sampled', 'sampling_min...  valid  5       1   \n",
       "5   {'dataset_name': 'xsum-sampled', 'sampling_min...  valid  5       1   \n",
       "6   {'dataset_name': 'xsum-sampled', 'sampling_min...  valid  5       1   \n",
       "7   {'dataset_name': 'xsum-sampled', 'sampling_min...  valid  5       1   \n",
       "8   {'dataset_name': 'xsum-sampled', 'sampling_min...  valid  5       1   \n",
       "9   {'dataset_name': 'xsum-sampled', 'sampling_min...   test  5       1   \n",
       "10  {'dataset_name': 'xsum-sampled', 'sampling_min...  valid  5       1   \n",
       "11  {'dataset_name': 'xsum-sampled', 'sampling_min...  valid  5       1   \n",
       "12  {'dataset_name': 'xsum-sampled', 'sampling_min...   test  5       1   \n",
       "13  {'dataset_name': 'xsum-sampled', 'sampling_min...  valid  5       1   \n",
       "14  {'dataset_name': 'xsum-sampled', 'sampling_min...   test  5       1   \n",
       "15  {'dataset_name': 'xsum-sampled', 'sampling_min...   test  5       1   \n",
       "16  {'dataset_name': 'xsum-sampled', 'sampling_min...  valid  5       1   \n",
       "17  {'dataset_name': 'xsum-sampled', 'sampling_min...   test  5       1   \n",
       "18  {'dataset_name': 'xsum-sampled', 'sampling_min...   test  5       1   \n",
       "19  {'dataset_name': 'xsum-sampled', 'sampling_min...  valid  5       1   \n",
       "20  {'dataset_name': 'xsum-sampled', 'sampling_min...   test  5       1   \n",
       "21  {'dataset_name': 'xsum-sampled', 'sampling_min...  valid  5       1   \n",
       "22  {'dataset_name': 'xsum-sampled', 'sampling_min...   test  5       1   \n",
       "23  {'dataset_name': 'xsum-sampled', 'sampling_min...  valid  5       1   \n",
       "24  {'dataset_name': 'xsum-sampled', 'sampling_min...   test  5       1   \n",
       "25  {'dataset_name': 'xsum-sampled', 'sampling_min...  valid  5       1   \n",
       "26                           {'demographic': 'white'}   test  5       1   \n",
       "27                           {'demographic': 'white'}   test  5       1   \n",
       "28  {'dataset_name': 'xsum-sampled', 'sampling_min...  valid  5       1   \n",
       "29  {'dataset_name': 'xsum-sampled', 'sampling_min...  valid  5       1   \n",
       "30  {'dataset_name': 'xsum-sampled', 'sampling_min...   test  5       1   \n",
       "31  {'dataset_name': 'xsum-sampled', 'sampling_min...  valid  5       1   \n",
       "32  {'dataset_name': 'xsum-sampled', 'sampling_min...   test  5       1   \n",
       "33  {'dataset_name': 'xsum-sampled', 'sampling_min...  valid  5       1   \n",
       "34  {'dataset_name': 'xsum-sampled', 'sampling_min...  valid  5       1   \n",
       "35  {'dataset_name': 'xsum-sampled', 'sampling_min...   test  5       1   \n",
       "36  {'dataset_name': 'xsum-sampled', 'sampling_min...   test  5       1   \n",
       "37  {'dataset_name': 'xsum-sampled', 'sampling_min...  valid  5       1   \n",
       "38  {'dataset_name': 'xsum-sampled', 'sampling_min...  valid  5       1   \n",
       "39  {'dataset_name': 'xsum-sampled', 'sampling_min...  valid  5       1   \n",
       "40  {'dataset_name': 'xsum-sampled', 'sampling_min...  valid  5       1   \n",
       "41  {'dataset_name': 'xsum-sampled', 'sampling_min...  valid  5       1   \n",
       "42  {'dataset_name': 'xsum-sampled', 'sampling_min...  valid  5       1   \n",
       "43  {'dataset_name': 'xsum-sampled', 'sampling_min...  valid  5       1   \n",
       "44  {'dataset_name': 'xsum-sampled', 'sampling_min...  valid  5       1   \n",
       "45  {'dataset_name': 'xsum-sampled', 'sampling_min...  valid  5       1   \n",
       "46  {'dataset_name': 'xsum-sampled', 'sampling_min...   test  5       1   \n",
       "47  {'dataset_name': 'xsum-sampled', 'sampling_min...  valid  5       1   \n",
       "48                           {'demographic': 'white'}   test  5       1   \n",
       "49                           {'demographic': 'white'}   test  5       1   \n",
       "50  {'dataset_name': 'xsum-sampled', 'sampling_min...  valid  5       1   \n",
       "51                           {'demographic': 'white'}   test  5       1   \n",
       "52  {'dataset_name': 'xsum-sampled', 'sampling_min...  valid  5       1   \n",
       "53  {'dataset_name': 'xsum-sampled', 'sampling_min...  valid  5       1   \n",
       "54  {'dataset_name': 'xsum-sampled', 'sampling_min...   test  5       1   \n",
       "\n",
       "    jaccard_unweighted  jaccard_weighted  token_unweighted  token_weighted  \n",
       "0             0.006667          0.006667          0.019737        0.019737  \n",
       "1             0.001916          0.001916          0.009506        0.009506  \n",
       "2             0.001912          0.001912          0.009488        0.009488  \n",
       "3             0.001969          0.001969          0.009766        0.009766  \n",
       "4             0.002710          0.002710          0.013405        0.013405  \n",
       "5             0.002066          0.002066          0.010246        0.010246  \n",
       "6             0.001901          0.001901          0.009434        0.009434  \n",
       "7             0.001946          0.001946          0.009653        0.009653  \n",
       "8             0.003268          0.003268          0.016129        0.016129  \n",
       "9             0.001919          0.001919          0.009524        0.009524  \n",
       "10            0.003984          0.003984          0.019763        0.019763  \n",
       "11            0.002688          0.002688          0.013298        0.013298  \n",
       "12            0.050000          0.050000          0.208333        0.208333  \n",
       "13            0.003861          0.003861          0.019011        0.019011  \n",
       "14            0.002404          0.002404          0.011905        0.011905  \n",
       "15            0.002755          0.002755          0.013624        0.013624  \n",
       "16            0.003788          0.003788          0.018657        0.018657  \n",
       "17            0.006250          0.006250          0.030488        0.030488  \n",
       "18            0.010526          0.010526          0.050505        0.050505  \n",
       "19            0.005263          0.005263          0.025773        0.025773  \n",
       "20            0.002933          0.002933          0.014493        0.014493  \n",
       "21            0.012500          0.012500          0.036585        0.036585  \n",
       "22            0.004673          0.004673          0.022936        0.022936  \n",
       "23            0.003759          0.003759          0.018519        0.018519  \n",
       "24            0.006116          0.006116          0.030211        0.030211  \n",
       "25            0.001873          0.001873          0.009294        0.009294  \n",
       "26            0.125000          0.125000          0.416667        0.416667  \n",
       "27            0.200000          0.200000          0.555556        0.555556  \n",
       "28            0.001946          0.001946          0.009653        0.009653  \n",
       "29            0.002227          0.001114          0.011038        0.005519  \n",
       "30            0.003115          0.001558          0.015385        0.007692  \n",
       "31            0.004386          0.004386          0.021552        0.021552  \n",
       "32            0.003086          0.003086          0.015244        0.015244  \n",
       "33            0.009346          0.009346          0.045045        0.045045  \n",
       "34            0.005025          0.005025          0.024631        0.024631  \n",
       "35            0.002778          0.002778          0.013736        0.013736  \n",
       "36            0.003003          0.003003          0.014837        0.014837  \n",
       "37            0.002273          0.002273          0.011261        0.011261  \n",
       "38            0.006993          0.006993          0.034014        0.034014  \n",
       "39            0.001873          0.001873          0.009294        0.009294  \n",
       "40            0.001946          0.001946          0.009653        0.009653  \n",
       "41            0.076923          0.076923          0.294118        0.294118  \n",
       "42            0.003839          0.003839          0.011429        0.011429  \n",
       "43            0.001942          0.001942          0.009634        0.009634  \n",
       "44            0.003810          0.003810          0.011342        0.011342  \n",
       "45            0.001949          0.001949          0.009671        0.009671  \n",
       "46            0.003846          0.003846          0.018939        0.018939  \n",
       "47            0.002967          0.002967          0.014663        0.014663  \n",
       "48            0.142857          0.071429          0.454545        0.227273  \n",
       "49            0.125000          0.062500          0.416667        0.208333  \n",
       "50            0.002577          0.001289          0.012755        0.006378  \n",
       "51            0.250000          0.250000          0.625000        0.625000  \n",
       "52            0.003077          0.003077          0.015198        0.015198  \n",
       "53            0.002033          0.002033          0.010081        0.010081  \n",
       "54            0.001949          0.001949          0.009671        0.009671  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/teo/OpenMined/PySyft/notebooks/helm/helm_syft.ipynb Cell 30\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/teo/OpenMined/PySyft/notebooks/helm/helm_syft.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from nltk import ngrams\n",
    "\n",
    "def compute_binary_overlap(instance_str, overlapping_ngram_counts, tokenizer, N, frequency = 0):\n",
    "        \"\"\" \n",
    "        Compute  binary overlap\n",
    "        If pass in frequency, include only the ngrams with count <= frequency\n",
    "        \"\"\"\n",
    "        tokens = tokenizer.tokenize(instance_str)\n",
    "        ngram_counts_dict = defaultdict(int)\n",
    "        \n",
    "        # construct a dict of ngram -> count\n",
    "        for ngram, count in overlapping_ngram_counts:\n",
    "            ngram = tuple(ast.literal_eval(ngram))\n",
    "            ngram_counts_dict[ngram] = count\n",
    "\n",
    "        metric_score = 0\n",
    "\n",
    "        for ngram in ngrams(tokens, N):\n",
    "            count = ngram_counts_dict[ngram]\n",
    "            if frequency == 0 or count <= frequency:\n",
    "                if count != 0:\n",
    "                    metric_score = 1\n",
    "                    break\n",
    "\n",
    "        overlap_metric = {\n",
    "            \"metric_score\": metric_score,\n",
    "            \"metric_protocol_spec\": {\n",
    "                \"partial_overlap_spec\": 0, #PartialOverlapSpec.binary,\n",
    "                \"frequency_spec\": {\n",
    "                    \"filter_value\": frequency,\n",
    "                    \"weighting\": False\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        return overlap_metric\n",
    "\n",
    "def compute_jaccard_overlap(instance_str, overlapping_ngram_counts, tokenizer, N, frequency = 0):\n",
    "    \"\"\" \n",
    "    Compute weighted and unweighted jaccard overlap\n",
    "    If pass in frequency, include only the ngrams with count <= frequency\n",
    "    \"\"\"\n",
    "    tokens = tokenizer.tokenize(instance_str)\n",
    "    ngram_counts_dict = defaultdict(int)\n",
    "    \n",
    "    # construct a dict of ngram -> count\n",
    "    for ngram, count in overlapping_ngram_counts:\n",
    "        ngram = tuple(ast.literal_eval(ngram))\n",
    "        ngram_counts_dict[ngram] = count\n",
    "\n",
    "    total_ngram_count = 0\n",
    "    counts = 0\n",
    "    weighted_score = 0\n",
    "\n",
    "    for ngram in ngrams(tokens, N):\n",
    "        count = ngram_counts_dict[ngram]\n",
    "        if frequency == 0 or count <= frequency:\n",
    "            if count != 0:\n",
    "                counts += 1\n",
    "                weighted_score += 1 / count\n",
    "        total_ngram_count += 1\n",
    "\n",
    "    unweighted_score = counts / total_ngram_count\n",
    "    weighted_score = weighted_score / total_ngram_count\n",
    "\n",
    "    unweighted_overlap_metric = {\n",
    "        \"metric_score\": unweighted_score ,\n",
    "        \"metric_protocol_spec\": {\n",
    "            \"partial_overlap_spec\": 1, #PartialOverlapSpec.jaccard,\n",
    "            \"frequency_spec\": {\n",
    "                \"filter_value\": frequency,\n",
    "                \"weighting\": False\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    weighted_overlap_metric = {\n",
    "        \"metric_score\": weighted_score ,\n",
    "        \"metric_protocol_spec\": {\n",
    "            \"partial_overlap_spec\": 1, #PartialOverlapSpec.jaccard,\n",
    "            \"frequency_spec\": {\n",
    "                \"filter_value\": frequency,\n",
    "                \"weighting\": True\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return unweighted_overlap_metric, weighted_overlap_metric\n",
    "\n",
    "# Token overlap\n",
    "def compute_token_overlap(instance_str, overlapping_ngram_counts, tokenizer, N, frequency = 0):\n",
    "    \"\"\" \n",
    "    Compute weighted and unweighted token overlap\n",
    "    If pass in frequency, include only the ngrams with count <= frequency\n",
    "    \"\"\"\n",
    "    tokens = tokenizer.tokenize(instance_str)\n",
    "    ngram_counts_dict = defaultdict(int)\n",
    "    \n",
    "    # construct a dict of ngram -> count\n",
    "    for ngram, count in overlapping_ngram_counts:\n",
    "        ngram = tuple(ast.literal_eval(ngram))\n",
    "        ngram_counts_dict[ngram] = count\n",
    "\n",
    "    total_token_count = 0\n",
    "    counts = 0\n",
    "    weighted_score = 0\n",
    "    weight = 0\n",
    "    token_budget = 0\n",
    "\n",
    "    for ngram in ngrams(tokens, N):\n",
    "        curr_count = ngram_counts_dict[ngram]\n",
    "\n",
    "        # either no frequency, or check current count is less than frequency\n",
    "        # or a previous contiguous count (weight != 0) less than frequency\n",
    "        if frequency == 0 or curr_count <= frequency or (weight != 0 and weight <= frequency):\n",
    "            if curr_count != 0:\n",
    "                token_budget = N\n",
    "                if weight > 0:\n",
    "                    weight = min(curr_count, weight)\n",
    "                else:\n",
    "                    weight = curr_count \n",
    "\n",
    "        if token_budget > 0:\n",
    "            token_budget -= 1\n",
    "            counts += 1\n",
    "            weighted_score += 1 / weight\n",
    "        else:\n",
    "            weight = 0\n",
    "        total_token_count += 1\n",
    "\n",
    "    for token in ngram[1:]:\n",
    "        if token_budget > 0:\n",
    "            token_budget -= 1\n",
    "            counts += 1\n",
    "            weighted_score += 1 / weight\n",
    "        total_token_count += 1\n",
    "\n",
    "    unweighted_score = counts / total_token_count\n",
    "    weighted_score = weighted_score / total_token_count\n",
    "\n",
    "    unweighted_overlap_metric = {\n",
    "        \"metric_score\": unweighted_score ,\n",
    "        \"metric_protocol_spec\": {\n",
    "            \"partial_overlap_spec\": 2, #PartialOverlapSpec.token,\n",
    "            \"frequency_spec\": {\n",
    "                \"filter_value\": frequency,\n",
    "                \"weighting\": False\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    weighted_overlap_metric = {\n",
    "        \"metric_score\": weighted_score ,\n",
    "        \"metric_protocol_spec\": {\n",
    "            \"partial_overlap_spec\": 2, #PartialOverlapSpec.token,\n",
    "            \"frequency_spec\": {\n",
    "                \"filter_value\": frequency,\n",
    "                \"weighting\": True\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return unweighted_overlap_metric, weighted_overlap_metric\n",
    "\n",
    "def compute_and_add_metrics(instance_str, overlapping_ngram_counts, tokenizer, entry_data_overlap_key, entry_overlap_metric_list, N, frequency = 0):\n",
    "\n",
    "    overlap_metric = compute_binary_overlap(instance_str, overlapping_ngram_counts, tokenizer, N, frequency)\n",
    "    binary_metric = {\"entry_data_overlap_key\": entry_data_overlap_key, \"overlap_metric\": overlap_metric}\n",
    "    entry_overlap_metric_list.append(binary_metric)\n",
    "\n",
    "    unweighted_overlap_metric, weighted_overlap_metric = compute_jaccard_overlap(instance_str, overlapping_ngram_counts, tokenizer, N, frequency)\n",
    "    unweighted_jaccard = {\"entry_data_overlap_key\": entry_data_overlap_key, \"overlap_metric\": unweighted_overlap_metric}\n",
    "    weighted_jaccard = {\"entry_data_overlap_key\": entry_data_overlap_key, \"overlap_metric\": weighted_overlap_metric}\n",
    "    entry_overlap_metric_list.append(unweighted_jaccard)\n",
    "    entry_overlap_metric_list.append(weighted_jaccard)\n",
    "\n",
    "    unweighted_overlap_metric, weighted_overlap_metric = compute_token_overlap(instance_str, overlapping_ngram_counts, tokenizer, N, frequency)\n",
    "    unweighted_token = {\"entry_data_overlap_key\": entry_data_overlap_key, \"overlap_metric\": unweighted_overlap_metric}\n",
    "    weighted_token = {\"entry_data_overlap_key\": entry_data_overlap_key, \"overlap_metric\": weighted_overlap_metric}\n",
    "    entry_overlap_metric_list.append(unweighted_token)\n",
    "    entry_overlap_metric_list.append(weighted_token)\n",
    "\n",
    "def save_metrics_to_jsonl(overlap_metrics, filename):\n",
    "    with open(filename, \"w\") as f:\n",
    "        for overlap_metric in overlap_metrics:\n",
    "            f.write(json.dumps(asdict_without_nones(overlap_metric), ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_path = 'short_new_scenario.jsonl'\n",
    "ngrams_path = 'test_output_ngrams'\n",
    "import cattrs\n",
    "N = 5\n",
    "\n",
    "# Read Ngrams\n",
    "ngram_jsons = open(ngrams_path, \"r\").readlines()\n",
    "entry_overlap_ngrams_list = []\n",
    "for ngram_json in ngram_jsons:\n",
    "    entry_overlap_ngrams = json.loads(ngram_json)\n",
    "    scenario_spec = entry_overlap_ngrams[\"entry_data_overlap_key\"][\"stats_key\"][\"light_scenario_key\"][\"scenario_spec\"]\n",
    "    entry_overlap_ngrams_list.append(entry_overlap_ngrams)\n",
    "            \n",
    "    def merge_entries(entry_overlap_ngrams_list):\n",
    "        overlapping_counts = defaultdict(int)\n",
    "        for entry_overlap_ngrams in entry_overlap_ngrams_list:\n",
    "            entry_data_overlap_key = entry_overlap_ngrams[\"entry_data_overlap_key\"]\n",
    "            overlapping_ngram_counts = entry_overlap_ngrams[\"overlapping_ngram_counts\"]\n",
    "            for ngram, count in overlapping_ngram_counts:\n",
    "                overlapping_counts[ngram] += count\n",
    "        overlapping_ngram_counts_list = []\n",
    "        for ngram, count in overlapping_counts.items():\n",
    "            overlapping_ngram_counts_list.append((ngram, count))\n",
    "        return [{\"entry_data_overlap_key\": entry_data_overlap_key, \"overlapping_ngram_counts\": overlapping_ngram_counts_list}]\n",
    "\n",
    "    # create entry_overlap_ngrams_dict, a dict of entry_data_overlap_key -> EntryOverlapNgrams\n",
    "    entry_overlap_ngrams_dict = defaultdict(list)\n",
    "    for entry_overlap_ngrams in entry_overlap_ngrams_list:\n",
    "        entry_data_overlap_key = entry_overlap_ngrams[\"entry_data_overlap_key\"]\n",
    "        overlapping_ngram_counts = entry_overlap_ngrams[\"overlapping_ngram_counts\"]\n",
    "        ngram_count = entry_data_overlap_key[\"stats_key\"][\"overlap_protocol_spec\"][\"n\"]\n",
    "        if ngram_count not in [N]:\n",
    "            continue\n",
    "        entry_overlap_ngrams_dict[str(entry_data_overlap_key)].append(entry_overlap_ngrams)\n",
    "        \n",
    "        # We need to merge entries if sharded by training data, since there'll be redundancy\n",
    "        # Can refactor to no list later\n",
    "        if len(entry_overlap_ngrams_dict[str(entry_data_overlap_key)]) > 1:\n",
    "            entry_overlap_ngrams_dict[entry_data_overlap_key] = merge_entries(entry_overlap_ngrams_dict[entry_data_overlap_key])\n",
    "\n",
    "    # Read Scenarios\n",
    "    light_scenarios = []\n",
    "    light_scenario_jsons = open(scenario_path, \"r\").readlines()\n",
    "    for light_scenario_json in light_scenario_jsons:\n",
    "        light_scenario_dict: dict = json.loads(light_scenario_json)\n",
    "\n",
    "        light_scenario_key_dict: dict = light_scenario_dict[\"scenario_key\"]\n",
    "        scenario_spec = str(light_scenario_key_dict[\"scenario_spec\"])\n",
    "        light_scenario_key = scenario_spec + '_' + light_scenario_key_dict[\"split\"]\n",
    "        light_instances = [\n",
    "            {\n",
    "                'input': instance_dict['input'], \n",
    "                'references': instance_dict['references'], \n",
    "                'id': instance_dict[\"id\"]\n",
    "            }\n",
    "            for instance_dict in light_scenario_dict[\"instances\"]\n",
    "        ]\n",
    "        light_scenarios.append({'scenario_key': light_scenario_key, 'instances': light_instances})\n",
    "    light_scenario_instance_dict = dict()\n",
    "    for light_scenario in light_scenarios:\n",
    "        instances = light_scenario[\"instances\"]\n",
    "        instance_dict = dict()\n",
    "        for instance in instances:\n",
    "            instance_dict[instance[\"id\"]] = instance\n",
    "        light_scenario_instance_dict[light_scenario[\"scenario_key\"]] = instance_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"{'scenario_spec': {'class_name': 'helm.benchmark.scenarios.summarization_scenario.SummarizationScenario', 'args': {'dataset_name': 'xsum-sampled', 'sampling_min_length': 50, 'sampling_max_length': 150, 'doc_max_length': 512}}, 'split': 'valid'}\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/teo/OpenMined/PySyft/notebooks/helm/helm_syft.ipynb Cell 33\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/teo/OpenMined/PySyft/notebooks/helm/helm_syft.ipynb#X43sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m data_overlap_stats_key \u001b[39m=\u001b[39m entry_data_overlap_key[\u001b[39m\"\u001b[39m\u001b[39mstats_key\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/teo/OpenMined/PySyft/notebooks/helm/helm_syft.ipynb#X43sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m light_scenario_key \u001b[39m=\u001b[39m data_overlap_stats_key[\u001b[39m\"\u001b[39m\u001b[39mlight_scenario_key\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/teo/OpenMined/PySyft/notebooks/helm/helm_syft.ipynb#X43sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m instance_dict \u001b[39m=\u001b[39m light_scenario_instance_dict[\u001b[39mstr\u001b[39;49m(light_scenario_key)]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/teo/OpenMined/PySyft/notebooks/helm/helm_syft.ipynb#X43sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mfor\u001b[39;00m entry_overlap_ngrams \u001b[39min\u001b[39;00m entry_overlap_ngrams_list:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/teo/OpenMined/PySyft/notebooks/helm/helm_syft.ipynb#X43sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     entry_data_overlap_key \u001b[39m=\u001b[39m entry_overlap_ngrams[\u001b[39m\"\u001b[39m\u001b[39mentry_data_overlap_key\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: \"{'scenario_spec': {'class_name': 'helm.benchmark.scenarios.summarization_scenario.SummarizationScenario', 'args': {'dataset_name': 'xsum-sampled', 'sampling_min_length': 50, 'sampling_max_length': 150, 'doc_max_length': 512}}, 'split': 'valid'}\""
     ]
    }
   ],
   "source": [
    "out_path = 'metrics'\n",
    "\n",
    "entry_overlap_metric_list = []\n",
    "import re\n",
    "from string import punctuation\n",
    "\n",
    "\n",
    "class LightTokenizer:\n",
    "    \"\"\"\n",
    "    Tokenize texts by splitting on whitespaces.\n",
    "    \"\"\"\n",
    "\n",
    "    def tokenize(self, text: str):\n",
    "        return text.split()\n",
    "    \n",
    "class DefaultTokenizer(LightTokenizer):\n",
    "    \"\"\"\n",
    "    Normalize and tokenize texts by converting all characters to the lower case and\n",
    "    splitting on whitespaces and punctuations.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.r = re.compile(r\"[\\s{}]+\".format(re.escape(punctuation)))\n",
    "\n",
    "    def tokenize(self, text: str):\n",
    "        return self.r.split(text.lower())\n",
    "\n",
    "tokenizer = DefaultTokenizer()\n",
    "for entry_data_overlap_key, entry_overlap_ngrams_list in entry_overlap_ngrams_dict.items():\n",
    "    entry_data_overlap_key = eval(entry_data_overlap_key)\n",
    "    data_overlap_stats_key = entry_data_overlap_key[\"stats_key\"]\n",
    "    light_scenario_key = data_overlap_stats_key[\"light_scenario_key\"]\n",
    "    instance_dict = light_scenario_instance_dict[str(light_scenario_key)]\n",
    "    for entry_overlap_ngrams in entry_overlap_ngrams_list:\n",
    "        entry_data_overlap_key = entry_overlap_ngrams[\"entry_data_overlap_key\"]\n",
    "        instance_id = entry_data_overlap_key[\"instance_id\"]\n",
    "        instance = instance_dict[instance_id]\n",
    "        part = entry_data_overlap_key[\"part\"]\n",
    "        overlapping_ngram_counts = entry_overlap_ngrams[\"overlapping_ngram_counts\"]\n",
    "        if part == 'input':\n",
    "            compute_and_add_metrics(instance[\"input\"], overlapping_ngram_counts, tokenizer, entry_data_overlap_key, entry_overlap_metric_list, N)\n",
    "            compute_and_add_metrics(instance[\"input\"], overlapping_ngram_counts, tokenizer, entry_data_overlap_key, entry_overlap_metric_list, N, frequency=10)\n",
    "        if part == 'references':\n",
    "            reference = ' '.join(instance.references)\n",
    "            compute_and_add_metrics(reference, overlapping_ngram_counts, tokenizer, entry_data_overlap_key, entry_overlap_metric_list, N)\n",
    "            compute_and_add_metrics(reference, overlapping_ngram_counts, tokenizer, entry_data_overlap_key, entry_overlap_metric_list, N, frequency=10)\n",
    "\n",
    "save_metrics_to_jsonl(entry_overlap_metric_list, out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "398.22px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
