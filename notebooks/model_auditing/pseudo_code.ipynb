{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node = sy.login(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "local_model = AutoTokenizer(name='gpt-2')\n",
    "# get the model from memory\n",
    "# safe to tmp folder\n",
    "# create SyftFiles\n",
    "# create a wrapper\n",
    "local_model_object = sy.ModelObject.from_model(local_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res: sy.SyftResult = node.models.submit(local_model_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all the model interfaces\n",
    "node.models.get_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptr_gpt2: ModelObject = node.models.search(\"gpt-2\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_data, prompts = load_local_data() \n",
    "action_obj = sy.ActionObject.from_obj(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This could mean that the model is mutable, we dont expect it to be better at this stage\n",
    "@sy.user_code(input_policy=sy.Match(model=ptr_gpt2, prompts=VariableInput(), retrain=VariableInput()))\n",
    "def train_and_eval(model,finetune_data,prompts,finetune=False):\n",
    "    if finetune:\n",
    "        for epoch in ...:\n",
    "            result = model.predict(finetune_data)\n",
    "            model.optimize(result)\n",
    "    toxic_report = hf.evaluate(model, prompts)\n",
    "    return model, toxic_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node.code.submit(train_and_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wait for approval from DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine tune the model\n",
    "node.code.train_and_eval(model=ptr_gpt2, data=..., prompts=..., finetune=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another session\n",
    "train_and_eval = node.code.search(name=\"train_and_eval\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the last model in the history of the function\n",
    "model_ptr = train_and_eval.output_policy.output_history.outputs[-1][\"model\"]\n",
    "\n",
    "# alternatively we could to\n",
    "# model_ptr = node.models.search('gpt-2')[0].get_latest_version()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run it just for eval\n",
    "_, toxic_score = node.code.train_and_eval(model=model_ptr, data=..., prompts=..., finetune=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
