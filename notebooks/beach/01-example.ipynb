{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676a3465-1c2c-429a-a311-845d9b98f8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# syft absolute\n",
    "import syft as sy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6809e1d8-f072-4402-ba1a-19e425803521",
   "metadata": {},
   "outputs": [],
   "source": [
    "node = sy.orchestra.launch(name=\"test-domain-1\", port=\"auto\", dev_mode=True, reset=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130e2e81-43c0-454d-9b85-0e3e4f00ad4c",
   "metadata": {},
   "source": [
    "# Admin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fad1198-27f2-4359-bb64-5fd0d64c5570",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_client = node.login(email=\"info@openmined.org\", password=\"changethis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87554148-16c8-4955-8346-20c3587e9069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# syft absolute\n",
    "from syft.client.api import APIRegistry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbe8f80-ea16-449f-9a4e-c3828c1e6fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "APIRegistry.get_all_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68e56e3-e51d-45c0-a855-3d8b2bbd060b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRIVATE_KEY = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d3464c-b3d0-4574-b575-027857e58d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVICE_ACCOUNT = {\n",
    "    \"type\": \"service_account\",\n",
    "    \"project_id\": \"project-enigma-415021\",\n",
    "    \"private_key_id\": \"0bd7cdd831f456f905fa98ad570740948bf7b7b9\",\n",
    "    \"private_key\": PRIVATE_KEY,\n",
    "    \"client_email\": \"vertex-test@project-enigma-415021.iam.gserviceaccount.com\",\n",
    "    \"client_id\": \"113559790781665979367\",\n",
    "    \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
    "    \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",
    "    \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",
    "    \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/vertex-test%40project-enigma-415021.iam.gserviceaccount.com\",\n",
    "    \"universe_domain\": \"googleapis.com\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efba6064-83ec-47ef-9015-99fa9ae5c8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@sy.mock_api_endpoint()\n",
    "def mock_run_vertex(\n",
    "    context,\n",
    "    prompt: str,\n",
    "    max_tokens: int = 50,\n",
    "    temperature: float = 0.1,\n",
    "    top_p: float = 1.0,\n",
    "    top_k: int = 1,\n",
    "    raw_response: bool = False,\n",
    ") -> str:\n",
    "    if raw_response:\n",
    "        return {\"prediction\": \"You get back a raw result\"}\n",
    "    else:\n",
    "        return {\"prediction\": \"You get back a result\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b22a160-d78f-48e9-8a56-f87f995684c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !uv pip install google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f644c5c1-be51-4a36-a7b2-fd303226eedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@sy.private_api_endpoint(\n",
    "    settings={\"SERVICE_ACCOUNT\": SERVICE_ACCOUNT},\n",
    ")\n",
    "def private_run_vertex(\n",
    "    context,\n",
    "    prompt: str,\n",
    "    max_tokens: int = 50,\n",
    "    temperature: float = 0.1,\n",
    "    top_p: float = 1.0,\n",
    "    top_k: int = 1,\n",
    "    raw_response: bool = False,\n",
    ") -> str:\n",
    "    # third party\n",
    "    from google.cloud import aiplatform\n",
    "    from google.oauth2 import service_account\n",
    "\n",
    "    try:\n",
    "        credentials = service_account.Credentials.from_service_account_info(\n",
    "            context.settings[\"SERVICE_ACCOUNT\"]\n",
    "        )\n",
    "\n",
    "        PROJECT_ID = \"project-enigma-415021\"\n",
    "        REGION = \"us-west1\"\n",
    "        ENDPOINT_ID = \"3213239169291649024\"\n",
    "        aip_endpoint_name = (\n",
    "            f\"projects/{PROJECT_ID}/locations/{REGION}/endpoints/{ENDPOINT_ID}\"\n",
    "        )\n",
    "        endpoint_vllm = aiplatform.Endpoint(aip_endpoint_name, credentials=credentials)\n",
    "        default_kwargs = {\n",
    "            \"prompt\": prompt,\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"temperature\": temperature,\n",
    "            \"top_p\": top_p,\n",
    "            \"top_k\": top_k,\n",
    "            \"raw_response\": raw_response,\n",
    "        }\n",
    "        instances = [\n",
    "            default_kwargs,\n",
    "        ]\n",
    "        response = endpoint_vllm.predict(instances=instances)\n",
    "        prediction = response.predictions[0]\n",
    "    except Exception:\n",
    "        prediction = \"Error: Please try again?\"\n",
    "    return {\"prediction\": prediction}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866524c5-e469-46d4-bc0a-a8570a572cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_endpoint = sy.TwinAPIEndpoint(\n",
    "    path=\"vertex.run\",\n",
    "    private_function=private_run_vertex,\n",
    "    mock_function=mock_run_vertex,\n",
    "    description=\"Run vertex model\",\n",
    ")\n",
    "new_endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4f82a9-050d-4ae3-80f4-56cc0c9c2927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use to delete if you want to add again (there is a seperate update API)\n",
    "domain_client.api.services.api.delete(endpoint_path=\"vertex.run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e14a21-ee78-486b-a5d4-4cf7de501139",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_client.api.services.api.add(endpoint=new_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb84bca5-fbc7-4fd0-a064-c71e120a1ca1",
   "metadata": {},
   "source": [
    "## Create Data Scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9dbd4f-1030-4b8d-b169-1cd39ddae723",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_client.register(\n",
    "    name=\"Jimmy Doe\",\n",
    "    email=\"jimmy@caltech.edu\",\n",
    "    password=\"abc123\",\n",
    "    password_verify=\"abc123\",\n",
    "    institution=\"Caltech\",\n",
    "    website=\"https://www.caltech.edu/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acfbc5c-d3a6-42de-80d4-e8355cbde851",
   "metadata": {},
   "source": [
    "# Data Scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0102f546-a9db-4b26-8ffa-cae84260059d",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = domain_client.api.services.user.search(name=\"Jimmy Doe\")\n",
    "user = users[0]\n",
    "user.mock_execution_permission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6e38cc-9019-49c9-9685-f72e1ca62a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "user.update(mock_execution_permission=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459fa86a-b17c-4688-a78c-2319144a1114",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = domain_client.api.services.user.search(name=\"Jimmy Doe\")\n",
    "user = users[0]\n",
    "user.mock_execution_permission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37894970-ae26-4a69-9279-60d7c3099985",
   "metadata": {},
   "outputs": [],
   "source": [
    "jimmy_client = node.login(email=\"jimmy@caltech.edu\", password=\"abc123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bd794b-67f6-4156-8b0d-3308d458dd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "jimmy_client.api.services.vertex.run.mock(prompt=\"test\", raw_response=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9b751a-236e-4b30-bbc4-8010aa182e36",
   "metadata": {},
   "source": [
    "## Create Input Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f61a0c-3d7f-48b9-af43-2da5578a9fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_policy = sy.MixedInputPolicy(\n",
    "    func=jimmy_client.api.services.vertex.run,\n",
    "    prompt=str,\n",
    "    max_tokens=int,\n",
    "    temperature=float,\n",
    "    top_p=float,\n",
    "    top_k=int,\n",
    "    raw_response=bool,\n",
    ")\n",
    "input_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e483823a-31e0-4c46-a347-dbd0e857ac2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4f7d0a-2dd6-484d-8724-9c62cb08ef6b",
   "metadata": {},
   "source": [
    "## Create Output Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49be96ea-b361-4c4d-9d8f-6c230d058584",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RateLimiter(sy.CustomOutputPolicy):\n",
    "    n_calls: int = 0\n",
    "    downloadable_output_args: list[str] = []\n",
    "    state: dict = {}\n",
    "\n",
    "    def __init__(self, n_calls=1, downloadable_output_args: list[str] = None):\n",
    "        self.downloadable_output_args = (\n",
    "            downloadable_output_args if downloadable_output_args is not None else []\n",
    "        )\n",
    "        self.n_calls = n_calls\n",
    "        self.state = {\"counts\": 0}\n",
    "\n",
    "    def public_state(self):\n",
    "        return self.state[\"counts\"]\n",
    "\n",
    "    def update_policy(self, context, outputs):\n",
    "        self.state[\"counts\"] += 1\n",
    "\n",
    "    def apply_to_output(self, context, outputs, update_policy=True):\n",
    "        if hasattr(outputs, \"syft_action_data\"):\n",
    "            outputs = outputs.syft_action_data\n",
    "        output_dict = {}\n",
    "        if self.state[\"counts\"] < self.n_calls:\n",
    "            for output_arg in self.downloadable_output_args:\n",
    "                output_dict[output_arg] = outputs[output_arg]\n",
    "            if update_policy:\n",
    "                self.update_policy(context, outputs)\n",
    "        else:\n",
    "            return \"You've hit the rate limit. Please contact the administrator.\"\n",
    "\n",
    "        output_dict[\"calls_remaining\"] = self.n_calls - self.state[\"counts\"]\n",
    "        return output_dict\n",
    "\n",
    "    def _is_valid(self, context):\n",
    "        return self.state[\"counts\"] < self.n_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6671d5be-55e1-4c8a-bde5-113ad71b5abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@sy.syft_function(\n",
    "    input_policy=input_policy,\n",
    "    output_policy=RateLimiter(n_calls=3, downloadable_output_args=[\"prediction\"]),\n",
    ")\n",
    "def my_vertex_func(\n",
    "    func,\n",
    "    prompt: str,\n",
    "    max_tokens: int = 50,\n",
    "    temperature: float = 0.1,\n",
    "    top_p: float = 1.0,\n",
    "    top_k: int = 1,\n",
    "    raw_response: bool = False,\n",
    "):\n",
    "    return func(\n",
    "        prompt=prompt,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        top_k=top_k,\n",
    "        raw_response=raw_response,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2d3075-65eb-4032-a025-22e0d0b3d948",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_vertex_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74a8193-2565-4dc4-a63d-b9349161cc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @sy.syft_function()\n",
    "#     input_policy=input_policy,\n",
    "#     output_policy=RateLimiter(n_calls=3, downloadable_output_args=[\"prediction\"]),\n",
    "# )\n",
    "# def my_vertex_func(\n",
    "#     func,\n",
    "#     prompt: str,\n",
    "#     max_tokens: int,\n",
    "#     temperature: float,\n",
    "#     top_p: float,\n",
    "#     top_k: int,\n",
    "#     raw_response: bool\n",
    "# ):\n",
    "#     return func(\n",
    "#         prompt=prompt,\n",
    "#         max_tokens=max_tokens,\n",
    "#         temperature=temperature,\n",
    "#         top_p=top_p,\n",
    "#         top_k=top_k,\n",
    "#         raw_response=raw_response\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c99074a-a75d-4f17-904d-05daf761fbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_vertex_func(func=jane_client.api.services.vertex.run, prompt=\"my prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5309dda0-baa5-41bf-8933-5b69445fb443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_func(*args, **kwargs):\n",
    "#     print(kwargs)\n",
    "#     return {\"prediction\": f\"Test API: {kwargs['prompt']}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cb4ee2-8c3c-4f1f-b08a-4e4652b068ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_vertex_func(func=test_func, prompt=\"my prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af39b60a-2ef9-4692-8106-8b349b01829c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4116ff-22b6-44b7-96b2-7bc3b861753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_project = sy.Project(\n",
    "    name=\"Vertex Model Access\",\n",
    "    description=\"Hi, I want to use this model 3 times\",\n",
    "    members=[jimmy_client],\n",
    ")\n",
    "\n",
    "new_project.create_code_request(my_vertex_func, jimmy_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1366087-7ab1-4bed-b21a-ba2ec99fa657",
   "metadata": {},
   "source": [
    "## Admin approves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501348e1-436b-4fc5-81e6-f868cad4899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_client.requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d66132b-6386-4afd-907b-07f5af827b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = domain_client.requests[-1]\n",
    "request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab1beb3-3c7b-4b86-9e53-0cdc3d237d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "request.approve()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3bc882-1f98-4479-a114-7f38eb5c4043",
   "metadata": {},
   "source": [
    "## Data Scientist runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef126cbf-286e-4220-96e9-8bfaabd744aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "jimmy_client.refresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193b88cb-7d77-4ea0-905d-48a4b56acfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "jimmy_client.code.my_vertex_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7137310f-d74f-46c8-982e-0383c6dd696c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = jimmy_client.code.my_vertex_func(\n",
    "    func=jimmy_client.api.services.vertex.run,\n",
    "    prompt=\"Who are you now?\",\n",
    "    max_tokens=50,\n",
    "    temperature=0.1,\n",
    "    top_p=1.0,\n",
    "    top_k=1,\n",
    "    raw_response=False,\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a3999f-c31a-43f1-8b13-60a5a98e83b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = jimmy_client.code.my_vertex_func(\n",
    "    func=jimmy_client.api.services.vertex.run,\n",
    "    prompt=\"Who are you now?\",\n",
    "    max_tokens=50,\n",
    "    temperature=0.1,\n",
    "    top_p=1.0,\n",
    "    top_k=1,\n",
    "    raw_response=False,\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112443fe-5246-4746-950e-c265d22ae3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = jimmy_client.code.my_vertex_func(\n",
    "    func=jimmy_client.api.services.vertex.run,\n",
    "    prompt=\"Who are you now?\",\n",
    "    max_tokens=50,\n",
    "    temperature=0.1,\n",
    "    top_p=1.0,\n",
    "    top_k=1,\n",
    "    raw_response=False,\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac1f478-78ab-4fa0-a334-2a4ddd6fa4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = jimmy_client.code.my_vertex_func(\n",
    "    func=jimmy_client.api.services.vertex.run,\n",
    "    prompt=\"Who are you now?\",\n",
    "    max_tokens=50,\n",
    "    temperature=0.1,\n",
    "    top_p=1.0,\n",
    "    top_k=1,\n",
    "    raw_response=False,\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a73ad14-7cc7-4103-abdc-5631f74d9df3",
   "metadata": {},
   "source": [
    "## Advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6aca7f-433c-4c9b-b184-62fb768e5b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c29ad7-3965-433d-b7c4-dd6511690cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow api endpoint code to generate a policy and code submission object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe097fd-99f4-4969-bc77-f04b2bb1da40",
   "metadata": {},
   "outputs": [],
   "source": [
    "@sy.private_api_endpoint()\n",
    "def private_user_function_creator(\n",
    "    context,\n",
    "    api_func,\n",
    "    n_calls: int,\n",
    "    name: str,\n",
    ") -> str:\n",
    "    # syft absolute\n",
    "    import syft as sy\n",
    "\n",
    "    # create input policy\n",
    "    input_policy = sy.MixedInputPolicy(\n",
    "        func=api_func,\n",
    "        prompt=str,\n",
    "        max_tokens=int,\n",
    "        temperature=float,\n",
    "        top_p=float,\n",
    "        top_k=int,\n",
    "        raw_response=bool,\n",
    "    )\n",
    "\n",
    "    class RateLimiter(sy.CustomOutputPolicy):\n",
    "        n_calls: int = 0\n",
    "        downloadable_output_args: list[str] = []\n",
    "        state: dict = {}\n",
    "\n",
    "        def __init__(self, n_calls=1, downloadable_output_args: list[str] = None):\n",
    "            self.downloadable_output_args = (\n",
    "                downloadable_output_args if downloadable_output_args is not None else []\n",
    "            )\n",
    "            self.n_calls = n_calls\n",
    "            self.state = {\"counts\": 0}\n",
    "\n",
    "        def public_state(self):\n",
    "            return self.state[\"counts\"]\n",
    "\n",
    "        def update_policy(self, context, outputs):\n",
    "            self.state[\"counts\"] += 1\n",
    "\n",
    "        def apply_to_output(self, context, outputs, update_policy=True):\n",
    "            if hasattr(outputs, \"syft_action_data\"):\n",
    "                outputs = outputs.syft_action_data\n",
    "            output_dict = {}\n",
    "            if self.state[\"counts\"] < self.n_calls:\n",
    "                for output_arg in self.downloadable_output_args:\n",
    "                    output_dict[output_arg] = outputs[output_arg]\n",
    "                if update_policy:\n",
    "                    self.update_policy(context, outputs)\n",
    "            else:\n",
    "                return \"You've hit the rate limit. Please contact the administrator.\"\n",
    "\n",
    "            output_dict[\"calls_remaining\"] = self.n_calls - self.state[\"counts\"]\n",
    "            return output_dict\n",
    "\n",
    "        def _is_valid(self, context):\n",
    "            return self.state[\"counts\"] < self.n_calls\n",
    "\n",
    "    @sy.syft_function(\n",
    "        input_policy=input_policy,\n",
    "        output_policy=RateLimiter(\n",
    "            n_calls=n_calls, downloadable_output_args=[\"prediction\"]\n",
    "        ),\n",
    "    )\n",
    "    def my_vertex_func(\n",
    "        func,\n",
    "        prompt: str,\n",
    "        max_tokens: int = 50,\n",
    "        temperature: float = 0.1,\n",
    "        top_p: float = 1.0,\n",
    "        top_k: int = 1,\n",
    "        raw_response: bool = False,\n",
    "    ):\n",
    "        return func(\n",
    "            prompt=prompt,\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            top_k=top_k,\n",
    "            raw_response=raw_response,\n",
    "        )\n",
    "\n",
    "    my_vertex_func.__name__ = name\n",
    "    return my_vertex_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee53e5a1-2f56-43e0-9523-1ac27e669ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@sy.mock_api_endpoint()\n",
    "def mock_user_function_creator(\n",
    "    context,\n",
    "    api_func,\n",
    "    n_calls: int,\n",
    "    name: str,\n",
    ") -> str:\n",
    "    # syft absolute\n",
    "    import syft as sy\n",
    "\n",
    "    # create input policy\n",
    "    input_policy = sy.MixedInputPolicy(\n",
    "        func=api_func,\n",
    "        prompt=str,\n",
    "        max_tokens=int,\n",
    "        temperature=float,\n",
    "        top_p=float,\n",
    "        top_k=int,\n",
    "        raw_response=bool,\n",
    "    )\n",
    "\n",
    "    class RateLimiter(sy.CustomOutputPolicy):\n",
    "        n_calls: int = 0\n",
    "        downloadable_output_args: list[str] = []\n",
    "        state: dict = {}\n",
    "\n",
    "        def __init__(self, n_calls=1, downloadable_output_args: list[str] = None):\n",
    "            self.downloadable_output_args = (\n",
    "                downloadable_output_args if downloadable_output_args is not None else []\n",
    "            )\n",
    "            self.n_calls = n_calls\n",
    "            self.state = {\"counts\": 0}\n",
    "\n",
    "        def public_state(self):\n",
    "            return self.state[\"counts\"]\n",
    "\n",
    "        def update_policy(self, context, outputs):\n",
    "            self.state[\"counts\"] += 1\n",
    "\n",
    "        def apply_to_output(self, context, outputs, update_policy=True):\n",
    "            if hasattr(outputs, \"syft_action_data\"):\n",
    "                outputs = outputs.syft_action_data\n",
    "            output_dict = {}\n",
    "            if self.state[\"counts\"] < self.n_calls:\n",
    "                for output_arg in self.downloadable_output_args:\n",
    "                    output_dict[output_arg] = outputs[output_arg]\n",
    "                if update_policy:\n",
    "                    self.update_policy(context, outputs)\n",
    "            else:\n",
    "                return \"You've hit the rate limit. Please contact the administrator.\"\n",
    "\n",
    "            output_dict[\"calls_remaining\"] = self.n_calls - self.state[\"counts\"]\n",
    "            return output_dict\n",
    "\n",
    "        def _is_valid(self, context):\n",
    "            return self.state[\"counts\"] < self.n_calls\n",
    "\n",
    "    @sy.syft_function(\n",
    "        input_policy=input_policy,\n",
    "        output_policy=RateLimiter(\n",
    "            n_calls=n_calls, downloadable_output_args=[\"prediction\"]\n",
    "        ),\n",
    "    )\n",
    "    def my_vertex_func(\n",
    "        func,\n",
    "        prompt: str,\n",
    "        max_tokens: int = 50,\n",
    "        temperature: float = 0.1,\n",
    "        top_p: float = 1.0,\n",
    "        top_k: int = 1,\n",
    "        raw_response: bool = False,\n",
    "    ):\n",
    "        return func(\n",
    "            prompt=prompt,\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            top_k=top_k,\n",
    "            raw_response=raw_response,\n",
    "        )\n",
    "\n",
    "    my_vertex_func.__name__ = name\n",
    "    return my_vertex_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0aa6611-66d2-4b0b-a9c3-a2b7f53164e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "creator_endpoint = sy.TwinAPIEndpoint(\n",
    "    path=\"vertex.create_code_request\",\n",
    "    private_function=private_user_function_creator,\n",
    "    mock_function=mock_user_function_creator,\n",
    "    description=\"Create a vertex code request\",\n",
    ")\n",
    "creator_endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35ccdc3-295c-4250-a3c3-c4e61def5574",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ad54e6-81b9-4488-8301-50841b321e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = domain_client.api.services.api.delete(\n",
    "    endpoint_path=\"vertex.create_code_request\"\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62fd28e-4479-4856-b640-13fe478e5450",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = domain_client.api.services.api.add(endpoint=creator_endpoint)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186bdb24-e419-488d-b5af-2ca6df34ad57",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_client.refresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9336cb5-f8d0-4de0-bd1f-bdb87b3a0022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to make the RemoteFunction serializable andchange what comes back to the user side from the Admin API\n",
    "# or add a context.submit as user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecec097-5974-411c-b6e8-08384e72e5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_client.api.services.vertex.create_code_request(\n",
    "    api_func=domain_client.api.services.vertex.run, n_calls=2, name=\"myfunc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a202c8d-7dda-42da-9046-f03a2a6b908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "jimmy_client.refresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65c5a35-2131-4042-bcd1-a1724f909ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jimmy_client.api.services.vertex.create_code_request(api_func=jimmy_client.api.services.vertex.run, n_calls=2, name=\"myfunc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a54bbe-8ce5-4c34-8079-cfadd260994d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_project = sy.Project(\n",
    "#     name=\"Vertex Model Access\",\n",
    "#     description=\"Hi, I want to use this model 3 times\",\n",
    "#     members=[jane_client],\n",
    "# )\n",
    "\n",
    "# new_project.create_code_request(code_obj, jane_client)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
