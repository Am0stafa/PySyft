{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Haiku Level 0 Data Scientist Experience - Chapter 4\n",
    "## Part 1 - New account registration and code execution requests\n",
    "\n",
    "Link to the original Haiku tutorial: https://dm-haiku.readthedocs.io/en/latest/notebooks/non_trainable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import syft as sy\n",
    "sy.requires(\">=0.8-beta\")\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import haiku as hk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register a client to the domain\n",
    "node = sy.orchestra.launch(name=\"test-domain-1\")\n",
    "guest_domain_client = node.client\n",
    "guest_domain_client.register(name=\"Jane Doe\", email=\"jane@caltech.edu\", password=\"abc123\", institution=\"Caltech\", website=\"https://www.caltech.edu/\")\n",
    "guest_domain_client.login(email=\"jane@caltech.edu\", password=\"abc123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function for code execution\n",
    "# ATTENTION: ALL LIBRARIES USED SHOULD BE DEFINED INSIDE THE FUNCTION CONTEXT!!!\n",
    "\n",
    "@sy.syft_function(input_policy=sy.ExactMatch(),\n",
    "                  output_policy=sy.SingleExecutionExactOutput())\n",
    "def training_subset():\n",
    "    import haiku as hk\n",
    "    import jax\n",
    "    import jax.numpy as jnp\n",
    "    import numpy as np\n",
    "    \n",
    "    num_classes = 10\n",
    "\n",
    "    def f(x):\n",
    "        return hk.nets.MLP([300, 100, num_classes])(x)\n",
    "\n",
    "    f = hk.transform(f)\n",
    "\n",
    "    def test(params, num_classes=num_classes):\n",
    "        x = np.arange(num_classes).reshape([num_classes, 1]).astype(np.float32)\n",
    "        y = jnp.argmax(f.apply(params, None, x), axis=-1)\n",
    "        for x, y in zip(x, y):\n",
    "            print(x, \"->\", y)\n",
    "\n",
    "    rng = jax.random.PRNGKey(42)\n",
    "    x = np.zeros([num_classes, 1])\n",
    "    params = f.init(rng, x)\n",
    "\n",
    "    print(\"before training\")\n",
    "    test(params)\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    sns.set_theme()\n",
    "\n",
    "    def plot_params(params):\n",
    "        fig, axs = plt.subplots(ncols=2, nrows=3)\n",
    "        fig.tight_layout()\n",
    "        fig.set_figwidth(12)\n",
    "        fig.set_figheight(6)\n",
    "        for row, module in enumerate(sorted(params)):\n",
    "            ax = axs[row][0]\n",
    "            sns.heatmap(params[module][\"w\"], cmap=\"YlGnBu\", ax=ax)\n",
    "            ax.title.set_text(f\"{module}/w\")\n",
    "\n",
    "            ax = axs[row][1]\n",
    "            b = np.expand_dims(params[module][\"b\"], axis=0)\n",
    "            sns.heatmap(b, cmap=\"YlGnBu\", ax=ax)\n",
    "            ax.title.set_text(f\"{module}/b\")\n",
    "\n",
    "    plot_params(params)\n",
    "    \n",
    "    def dataset(*, batch_size, num_records):\n",
    "        for _ in range(num_records):\n",
    "            y = np.arange(num_classes)\n",
    "            y = np.random.permutation(y)[:batch_size]\n",
    "            x = y.reshape([batch_size, 1]).astype(np.float32)\n",
    "            yield x, y\n",
    "\n",
    "    for x, y in dataset(batch_size=4, num_records=5):\n",
    "        print(\"x :=\", x.tolist(), \"y :=\", y)\n",
    "\n",
    "    # Partition our params into trainable and non trainable explicitly.\n",
    "    trainable_params, non_trainable_params = hk.data_structures.partition(\n",
    "        lambda m, n, p: m != \"mlp/~/linear_1\", params)\n",
    "\n",
    "    print(\"trainable:\", list(trainable_params))\n",
    "    print(\"non_trainable:\", list(non_trainable_params))\n",
    "    \n",
    "    \n",
    "    def loss_fn(trainable_params, non_trainable_params, images, labels):\n",
    "        # NOTE: We need to combine trainable and non trainable before calling apply.\n",
    "        params = hk.data_structures.merge(trainable_params, non_trainable_params)\n",
    "\n",
    "        # NOTE: From here on this is a standard softmax cross entropy loss.\n",
    "        logits = f.apply(params, None, images)\n",
    "        labels = jax.nn.one_hot(labels, logits.shape[-1])\n",
    "        return -jnp.sum(labels * jax.nn.log_softmax(logits)) / labels.shape[0]\n",
    "\n",
    "    def sgd_step(params, grads, *, lr):\n",
    "        return jax.tree_util.tree_map(lambda p, g: p - g * lr, params, grads)\n",
    "\n",
    "    def train_step(trainable_params, non_trainable_params, x, y):\n",
    "        # NOTE: We will only compute gradients wrt `trainable_params`.\n",
    "        trainable_params_grads = jax.grad(loss_fn)(trainable_params,\n",
    "                                                    non_trainable_params, x, y)\n",
    "\n",
    "        # NOTE: We are only updating `trainable_params`.\n",
    "        trainable_params = sgd_step(trainable_params, trainable_params_grads, lr=0.1)\n",
    "        return trainable_params\n",
    "\n",
    "    train_step = jax.jit(train_step)\n",
    "\n",
    "    for x, y in dataset(batch_size=num_classes, num_records=10000):\n",
    "        # NOTE: In our training loop only our trainable parameters are updated.\n",
    "        trainable_params = train_step(trainable_params, non_trainable_params, x, y)\n",
    "\n",
    "    # Merge params again for inference.\n",
    "    params = hk.data_structures.merge(trainable_params, non_trainable_params)\n",
    "\n",
    "    print(\"after training\")\n",
    "    test(params)\n",
    "    test(params, num_classes=num_classes+10)\n",
    "    plot_params(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test our function locally \n",
    "training_subset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit the function for code execution\n",
    "guest_domain_client.api.services.code.request_code_execution(training_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guest_domain_client.api.services.code.training_subset()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Go to the Data Owner Notebook for Part 2!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Downloading the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guest_domain_client._api = None\n",
    "_ = guest_domain_client.api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = guest_domain_client.api.services.code.training_subset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.get_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.get_stderr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.get_plot().show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySyft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
